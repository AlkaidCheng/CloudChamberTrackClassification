{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VariationalQuantumClassifier_Walkthrough.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORQlOJwxhuhJ7w/fvUhDlf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlkaidCheng/CloudChamberTrackClassification/blob/master/VariationalQuantumClassifier_Walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMEp8G-khnYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a9d7a49-6aa2-4861-8eb3-0d11c7eff506"
      },
      "source": [
        "!pip install quple"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting quple\n",
            "  Downloading https://files.pythonhosted.org/packages/64/62/64b25987fc412852c9bc774155bc9e321cda024dd4264158198e52b2fda3/quple-0.5.5.0-py3-none-any.whl\n",
            "Collecting cirq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/5b/6f8cb54ea8c0041ad9c8e4ece07cb5ca9eb1c29de68e68795b4a40d90cc6/cirq-0.8.2-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 10.4MB/s \n",
            "\u001b[?25hCollecting tensorflow-quantum==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/60/3c73e8c4b68efdd84927e3a2975c52fbf9af50305c3dbecbf0557b8f7b73/tensorflow_quantum-0.3.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 34.2MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from quple) (1.18.5)\n",
            "Collecting freezegun~=0.3.15\n",
            "  Downloading https://files.pythonhosted.org/packages/17/5d/1b9d6d3c7995fff473f35861d674e0113a5f0bd5a72fe0199c3f254665c7/freezegun-0.3.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (1.4.1)\n",
            "Requirement already satisfied: networkx~=2.4 in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (2.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (3.7.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (1.0.5)\n",
            "Requirement already satisfied: protobuf~=3.12.0 in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (3.12.4)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (2.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (1.1.1)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (3.2.2)\n",
            "Requirement already satisfied: requests~=2.18 in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (0.7)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from cirq->quple) (1.16.0)\n",
            "Collecting pathos==0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/a2/cd59f73d5ede4f122687bf8f63de5d671c9561e493ca699241f05b038278/pathos-0.2.5.tar.gz (162kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (1.30.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (1.1.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 39.9MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 42.0MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (1.1.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->quple) (0.34.2)\n",
            "Requirement already satisfied: python-dateutil!=2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from freezegun~=0.3.15->cirq->quple) (2.8.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx~=2.4->cirq->quple) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->cirq->quple) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf~=3.12.0->cirq->quple) (49.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->cirq->quple) (1.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->cirq->quple) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->cirq->quple) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->cirq->quple) (0.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.18->cirq->quple) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.18->cirq->quple) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.18->cirq->quple) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.18->cirq->quple) (2020.6.20)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq->quple) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq->quple) (1.52.0)\n",
            "Collecting ppft>=1.6.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/fb/fa21f6e9aedc4823448473ed96e8eab64af1cb248c18165f045a90e1c6b4/ppft-1.6.6.2.zip (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from pathos==0.2.5->tensorflow-quantum==0.3.0->quple) (0.3.2)\n",
            "Collecting pox>=0.2.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/0c/ec447fb0ed88bc1c09bf0dadf00e40ea05fda17e841d15bb351a52d9e192/pox-0.2.8.zip (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess>=0.70.9 in /usr/local/lib/python3.6/dist-packages (from pathos==0.2.5->tensorflow-quantum==0.3.0->quple) (0.70.10)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->quple) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->quple) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->quple) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->quple) (2.10.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq->quple) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq->quple) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq->quple) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->quple) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->quple) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq->quple) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->quple) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->quple) (3.1.0)\n",
            "Building wheels for collected packages: pathos, gast, ppft, pox\n",
            "  Building wheel for pathos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathos: filename=pathos-0.2.5-cp36-none-any.whl size=77577 sha256=b2311f662b84579481e3d49a7f7d8eefe1455dad6845b1c7d8fe50bc4abdb008\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/6d/83/90b0c3d2c271da2c4850731e894798c98f8dbedbac74e8eff0\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=e548bca66b8947af8d15be32f596657b8d745e6093fcb27dee75bb7ae035bc4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for ppft (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ppft: filename=ppft-1.6.6.2-cp36-none-any.whl size=64743 sha256=dc95c19ba90d19d4a512dfc1762a68a10685c82053a8d9cfe7e6b3e99c84b81c\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/d2/2d/0ee21ede61786bb13247dbc69079373fd500c2bb0481913084\n",
            "  Building wheel for pox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pox: filename=pox-0.2.8-cp36-none-any.whl size=28290 sha256=b5ab83118b12d53e305a74387cddad7b0879ffa27e57ce04f779f50556762c4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/ed/ce/a93103746b327e18bffaeb99ba0d57a88b392f31d719cea700\n",
            "Successfully built pathos gast ppft pox\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-quantum 0.3.0 has requirement cirq==0.8.0, but you'll have cirq 0.8.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-quantum 0.3.0 has requirement sympy==1.4, but you'll have sympy 1.1.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: freezegun, cirq, ppft, pox, pathos, tensorflow-quantum, tensorboard, tensorflow-estimator, gast, keras-applications, tensorflow, quple\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed cirq-0.8.2 freezegun-0.3.15 gast-0.2.2 keras-applications-1.0.8 pathos-0.2.5 pox-0.2.8 ppft-1.6.6.2 quple-0.5.5.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tensorflow-quantum-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEcyRsSwhn4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "abc2b04f-94e3-4dd4-82af-757c12ab1ad2"
      },
      "source": [
        "# download training data (hmumu 2jet)\n",
        "!wget -O hmumu_2jet.tar.gz https://cernbox.cern.ch/index.php/s/frrpvyVfSPYdMSk/download\n",
        "!tar -zxf hmumu_2jet.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-09 14:22:49--  https://cernbox.cern.ch/index.php/s/frrpvyVfSPYdMSk/download\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 188.184.97.72, 137.138.120.151, 128.142.32.26, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|188.184.97.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648491 (1.6M) [application/gzip]\n",
            "Saving to: ‘hmumu_2jet.tar.gz’\n",
            "\n",
            "hmumu_2jet.tar.gz   100%[===================>]   1.57M  1.72MB/s    in 0.9s    \n",
            "\n",
            "Last-modified header invalid -- time-stamp ignored.\n",
            "2020-08-09 14:22:52 (1.72 MB/s) - ‘hmumu_2jet.tar.gz’ saved [1648491/1648491]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX4TrCPohxuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a5024231-1799-4f42-b9db-2cfffb6e1320"
      },
      "source": [
        "import numpy as np\n",
        "# prepare training data\n",
        "data = np.load('hmumu_twojet_0719.npy')\n",
        "x = data[:,:-1]\n",
        "y = data[:,-1]\n",
        "print('Input Variables')\n",
        "print(x)\n",
        "print('Labels')\n",
        "print(y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Variables\n",
            "[[ 1.35123826e+02  9.97897017e-01  9.58638570e-01 ...  4.58769383e-01\n",
            "  -3.05654504e+00  1.80854129e+03]\n",
            " [ 2.43290406e+02  3.03747750e-01  6.74568519e-01 ... -1.34468994e+00\n",
            "  -2.72506172e+00  5.11933555e+02]\n",
            " [ 1.64464537e+02 -5.81922591e-02  5.42151745e-02 ... -6.23148328e-01\n",
            "   3.07514485e+00  3.44958465e+02]\n",
            " ...\n",
            " [ 2.16542712e+01 -3.05524425e+00  4.59151309e-01 ...  9.26630829e-01\n",
            "   3.08020790e+00  5.62347204e+02]\n",
            " [ 4.19387585e+01  1.89239955e+00  4.48033832e-01 ...  1.73410377e+00\n",
            "  -2.62992120e+00  1.44320990e+02]\n",
            " [ 9.33202609e+01  8.70685882e-01  8.74988118e-01 ... -1.21892943e+00\n",
            "   2.85587492e+00  2.03240716e+02]]\n",
            "Labels\n",
            "[1. 1. 1. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFVk-MoNh2ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's say we want to train on a circuit with 5 qubit\n",
        "n_qubit = 5\n",
        "# let's say we want to train on 1000 events\n",
        "n_event = 1000"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp2COk0sh3yG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00bd258e-681c-4623-9c3f-b6f8c24d6265"
      },
      "source": [
        "# prepare data preprocessors from sklearn\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "# we apply 3 data preprocessors\n",
        "# 1. PCA to reduce the dimension to 5 to fit the 5 qubit circuit\n",
        "# 2. StandardScaler to standardize features by removing the mean and scaling to unit variance\n",
        "# 3. MinMaxScaler to bound the data in the range [-1,+1]\n",
        "preprocessors = [PCA(n_components=n_qubit, random_state=3), StandardScaler(), MinMaxScaler((-1,1))]\n",
        "from quple.components.data_preparation import prepare_train_val_test\n",
        "# split the data into training set, validation set and test set\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = prepare_train_val_test(x, y, train_size=n_event, val_size=n_event, test_size=n_event, preprocessors=preprocessors, stratify=y)\n",
        "print('Training Dataset')\n",
        "print(x_train)\n",
        "print('Training Labels')\n",
        "print(y_train)\n",
        "print('Validation Dataset')\n",
        "print(x_val)\n",
        "print('Validation Labels')\n",
        "print(y_val)\n",
        "print('Test Dataset')\n",
        "print(x_test)\n",
        "print('Test Labels')\n",
        "print(y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset\n",
            "[[-4.34169963e-03 -6.26640732e-01 -4.98983735e-01 -7.89897273e-02\n",
            "   5.83961166e-01]\n",
            " [-9.15518399e-01 -4.44125411e-01 -3.60450171e-01 -9.11948154e-04\n",
            "  -3.85094860e-01]\n",
            " [-9.29266111e-01 -4.55227712e-01 -4.64185740e-01 -1.02825104e-01\n",
            "  -1.18712114e-01]\n",
            " ...\n",
            " [-9.09277900e-01 -4.32655424e-01 -5.87509278e-01  9.57256218e-03\n",
            "  -3.08770996e-01]\n",
            " [-8.31883410e-01 -6.51868551e-01 -5.17791015e-01  3.20667031e-02\n",
            "   5.67585871e-02]\n",
            " [-9.41304583e-01 -4.46796651e-01 -4.28132769e-01  8.56886629e-02\n",
            "  -1.50095512e-01]]\n",
            "Training Labels\n",
            "[1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.\n",
            " 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
            " 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
            "Validation Dataset\n",
            "[[-0.96020606 -0.56440119 -0.39165098  0.03717537 -0.14854985]\n",
            " [-0.71950495 -0.36197205 -0.57964526 -0.10661007 -0.10615145]\n",
            " [-0.97559266 -0.5087389  -0.61162314 -0.06223409 -0.16947975]\n",
            " ...\n",
            " [-0.77767885 -0.32529265  0.12394697  0.17451655  0.10166876]\n",
            " [-0.61731869 -0.59572714 -0.24067525  0.04772778 -0.13598358]\n",
            " [-0.23403369 -0.36204069 -0.77110292 -0.22202075 -0.3709768 ]]\n",
            "Validation Labels\n",
            "[0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1.\n",
            " 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
            " 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1.\n",
            " 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
            "Test Dataset\n",
            "[[-5.61508794e-01 -5.65776177e-01 -5.99620816e-01 -2.05728745e-02\n",
            "  -2.96307277e-01]\n",
            " [-7.09472123e-01 -7.16175277e-01 -5.20451699e-01 -6.40644291e-03\n",
            "  -2.08415839e-01]\n",
            " [-8.91901141e-01 -4.36164551e-01 -5.44054532e-01  1.42808620e-02\n",
            "  -3.61918941e-01]\n",
            " ...\n",
            " [-9.18965500e-01 -1.96857426e-01 -5.14302113e-01  1.43911873e-01\n",
            "  -3.07152645e-01]\n",
            " [-8.54030977e-01 -5.07962488e-01 -1.09204145e-01  7.54541868e-02\n",
            "   2.15320134e-01]\n",
            " [-9.84144478e-01 -6.18655735e-01 -5.00344658e-01  4.90646016e-04\n",
            "  -1.84152762e-01]]\n",
            "Test Labels\n",
            "[1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
            " 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0.\n",
            " 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1.\n",
            " 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
            " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmBkbpeFh9vU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "b7e1d761-fd85-4de2-98c5-5b97d05db995"
      },
      "source": [
        "from quple.data_encoding import FirstOrderExpansion\n",
        "# let's try the first order expansion encoding circuit with depth 2\n",
        "encoding_circuit = FirstOrderExpansion(feature_dimension=n_qubit, copies=2)\n",
        "print(encoding_circuit)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 0): ───H───Rz(pi*x_0)───H───Rz(pi*x_0)───\n",
            "\n",
            "(0, 1): ───H───Rz(pi*x_1)───H───Rz(pi*x_1)───\n",
            "\n",
            "(0, 2): ───H───Rz(pi*x_2)───H───Rz(pi*x_2)───\n",
            "\n",
            "(0, 3): ───H───Rz(pi*x_3)───H───Rz(pi*x_3)───\n",
            "\n",
            "(0, 4): ───H───Rz(pi*x_4)───H───Rz(pi*x_4)───\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe1Jil9rh_rD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "e16451a6-cafd-4340-9f70-bb2a17ebe280"
      },
      "source": [
        "from quple.trial_wavefunction import EfficientSU2\n",
        "# let's try the Efficient SU2 variational circuit with depth 2\n",
        "variational_circuit = EfficientSU2(n_qubit=n_qubit, copies=2)\n",
        "# let's add an RZ layer to increase the number of training variables\n",
        "variational_circuit.add_rotation_layer(['RZ'])\n",
        "# add readout qubit and entangle it to all other qubits\n",
        "variational_circuit.add_readout('XX')\n",
        "print(variational_circuit)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             ┌──┐       ┌──┐                                             ┌──┐       ┌──┐\n",
            "(-1, -1): ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────XX──────────XX──────────XX──────────XX──────────XX──────────\n",
            "                                                                                                                                          │           │           │           │           │\n",
            "(0, 0): ─────Ry(θ_0)───Rz(θ_5)───@───@───@────@────────────────────────Ry(θ_10)───Rz(θ_15)───@───@───@────@────────────────────Rz(θ_20)───XX^(θ_25)───┼───────────┼───────────┼───────────┼───────────\n",
            "                                 │   │   │    │                                              │   │   │    │                                           │           │           │           │\n",
            "(0, 1): ─────Ry(θ_1)───Rz(θ_6)───X───┼───┼────┼@────@────@─────────────Ry(θ_11)───Rz(θ_16)───X───┼───┼────┼@────@────@─────────Rz(θ_21)───────────────XX^(θ_26)───┼───────────┼───────────┼───────────\n",
            "                                     │   │    ││    │    │                                       │   │    ││    │    │                                            │           │           │\n",
            "(0, 2): ─────Ry(θ_2)───Rz(θ_7)───────X───┼────┼X────┼────┼@────@───────Ry(θ_12)───Rz(θ_17)───────X───┼────┼X────┼────┼@────@───Rz(θ_22)───────────────────────────XX^(θ_27)───┼───────────┼───────────\n",
            "                                         │    │     │    ││    │                                     │    │     │    ││    │                                                  │           │\n",
            "(0, 3): ─────Ry(θ_3)───Rz(θ_8)───────────X────┼─────X────┼X────┼───@───Ry(θ_13)───Rz(θ_18)───────────X────┼─────X────┼X────┼───@──────────Rz(θ_23)────────────────────────────XX^(θ_28)───┼───────────\n",
            "                                              │          │     │   │                                      │          │     │   │                                                          │\n",
            "(0, 4): ─────Ry(θ_4)───Rz(θ_9)────────────────X──────────X─────X───X───Ry(θ_14)───Rz(θ_19)────────────────X──────────X─────X───X──────────Rz(θ_24)────────────────────────────────────────XX^(θ_29)───\n",
            "                                             └──┘       └──┘                                             └──┘       └──┘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xd94sKMnNhr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "da067ff5-5947-445a-b30f-9f9a920f0037"
      },
      "source": [
        "import tensorflow as tf\n",
        "from quple.classifiers.variational_quantum_classifier import VQC\n",
        "from quple.classifiers.vqc_logger import VQCLogger\n",
        "# construct the vqc model\n",
        "vqc = VQC(encoding_circuit, variational_circuit, activation='sigmoid',\n",
        "          optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['binary_accuracy','AUC'], loss='mse',\n",
        "          readout=[variational_circuit.readout_measurement()], trainable_dense_layer=False)\n",
        "logger = VQCLogger()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Registered encoding circuit with feature dimension: 5\n",
            "Registered variational circuit with number of parameters: 30\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tizl8BAQnbmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dcc4a3d9-f3ce-404b-a71b-046038547f6e"
      },
      "source": [
        "# let's begin our training\n",
        "vqc.run(x_train, y_train, x_val, y_val, x_test, y_test, batch_size=64, epochs=100, callbacks=[logger])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting circuits to tensors...\n",
            "Converting circuits to tensors...\n",
            "2020-08-09 14:27:23,143 [MainThread  ][INFO ]  ######## Executing VQC with the following attributes ########\n",
            "2020-08-09 14:27:23,144 [MainThread  ][INFO ]  Feature Dimension: 5\n",
            "2020-08-09 14:27:23,147 [MainThread  ][INFO ]  Number of Qubits: 6\n",
            "2020-08-09 14:27:23,149 [MainThread  ][INFO ]  Qubit Layout: [cirq.GridQubit(-1, -1), cirq.GridQubit(0, 0), cirq.GridQubit(0, 1), cirq.GridQubit(0, 2), cirq.GridQubit(0, 3), cirq.GridQubit(0, 4)]\n",
            "2020-08-09 14:27:23,151 [MainThread  ][INFO ]  Encoding Circuit: FirstOrderExpansion\n",
            "2020-08-09 14:27:23,153 [MainThread  ][INFO ]  Encoding Map: self_product\n",
            "2020-08-09 14:27:23,157 [MainThread  ][INFO ]  Variational Circuit: EfficientSU2\n",
            "2020-08-09 14:27:23,159 [MainThread  ][INFO ]  Circuit Parameters: ['θ_0', 'θ_1', 'θ_10', 'θ_11', 'θ_12', 'θ_13', 'θ_14', 'θ_15', 'θ_16', 'θ_17', 'θ_18', 'θ_19', 'θ_2', 'θ_20', 'θ_21', 'θ_22', 'θ_23', 'θ_24', 'θ_25', 'θ_26', 'θ_27', 'θ_28', 'θ_29', 'θ_3', 'θ_4', 'θ_5', 'θ_6', 'θ_7', 'θ_8', 'θ_9']\n",
            "2020-08-09 14:27:23,161 [MainThread  ][INFO ]  Number of Parameters: 30\n",
            "2020-08-09 14:27:23,163 [MainThread  ][INFO ]  Optimizer: Adam\n",
            "2020-08-09 14:27:23,164 [MainThread  ][INFO ]  Metrics: ['binary_accuracy', 'AUC']\n",
            "2020-08-09 14:27:23,167 [MainThread  ][INFO ]  Loss Function: ['mean_squared_error']\n",
            "2020-08-09 14:27:23,168 [MainThread  ][INFO ]  Activation Function: sigmoid\n",
            "2020-08-09 14:27:23,170 [MainThread  ][INFO ]  Training Size: 1000\n",
            "2020-08-09 14:27:23,171 [MainThread  ][INFO ]  Validation Size: 1000\n",
            "2020-08-09 14:27:23,172 [MainThread  ][INFO ]  Test Size: 1000\n",
            "2020-08-09 14:27:23,174 [MainThread  ][INFO ]  Batch Size: 64\n",
            "2020-08-09 14:27:23,176 [MainThread  ][INFO ]  Number of Epochs: 100\n",
            "2020-08-09 14:27:23,222 [MainThread  ][INFO ]  ######## Training Begins ########\n",
            "2020-08-09 14:27:23,223 [MainThread  ][INFO ]  Number of samples for Training: 1000\n",
            "2020-08-09 14:27:23,227 [MainThread  ][INFO ]  Number of Epochs: 100\n",
            "2020-08-09 14:27:23,229 [MainThread  ][INFO ]  Batch Size: 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 16s 16ms/sample - loss: 0.2477 - binary_accuracy: 0.6820 - AUC: 0.7133 - val_loss: 0.2457 - val_binary_accuracy: 0.6360 - val_AUC: 0.7803\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2439 - binary_accuracy: 0.6460 - AUC: 0.7824 - val_loss: 0.2429 - val_binary_accuracy: 0.6210 - val_AUC: 0.7909\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2418 - binary_accuracy: 0.6360 - AUC: 0.8008 - val_loss: 0.2412 - val_binary_accuracy: 0.6350 - val_AUC: 0.8242\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2404 - binary_accuracy: 0.6690 - AUC: 0.8257 - val_loss: 0.2402 - val_binary_accuracy: 0.6570 - val_AUC: 0.8335\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2395 - binary_accuracy: 0.6720 - AUC: 0.8312 - val_loss: 0.2396 - val_binary_accuracy: 0.6590 - val_AUC: 0.8333\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2391 - binary_accuracy: 0.6780 - AUC: 0.8240 - val_loss: 0.2392 - val_binary_accuracy: 0.6700 - val_AUC: 0.8357\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2389 - binary_accuracy: 0.6900 - AUC: 0.8221 - val_loss: 0.2391 - val_binary_accuracy: 0.6780 - val_AUC: 0.8285\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6900 - AUC: 0.8119 - val_loss: 0.2392 - val_binary_accuracy: 0.6730 - val_AUC: 0.8244\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8037 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8190\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6890 - AUC: 0.8058 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8284\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6970 - AUC: 0.8124 - val_loss: 0.2391 - val_binary_accuracy: 0.6890 - val_AUC: 0.8291\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8132 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8299\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8097 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8251\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6960 - AUC: 0.8120 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8289\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8073 - val_loss: 0.2391 - val_binary_accuracy: 0.6800 - val_AUC: 0.8177\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8081 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8254\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8098 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8246\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8087 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8300\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6890 - AUC: 0.8075 - val_loss: 0.2391 - val_binary_accuracy: 0.6790 - val_AUC: 0.8173\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8058 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8284\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8120 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8284\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8113 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8206\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8084 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8280\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6960 - AUC: 0.8127 - val_loss: 0.2391 - val_binary_accuracy: 0.6880 - val_AUC: 0.8302\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8095 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8207\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8044 - val_loss: 0.2391 - val_binary_accuracy: 0.6800 - val_AUC: 0.8181\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6950 - AUC: 0.8107 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8300\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8078 - val_loss: 0.2392 - val_binary_accuracy: 0.6780 - val_AUC: 0.8153\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8079 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8300\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8076 - val_loss: 0.2392 - val_binary_accuracy: 0.6780 - val_AUC: 0.8165\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8093 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8251\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8058 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8258\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8092 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8239\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8073 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8300\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6900 - AUC: 0.8076 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8174\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8096 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8290\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 16s 16ms/sample - loss: 0.2388 - binary_accuracy: 0.6960 - AUC: 0.8101 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8286\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8060 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8178\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8096 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8262\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8076 - val_loss: 0.2391 - val_binary_accuracy: 0.6810 - val_AUC: 0.8178\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8075 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8254\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8065 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8223\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8093 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8251\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6890 - AUC: 0.8047 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8181\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8122 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8283\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8061 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8271\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8117 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8284\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8114 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8264\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8068 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8250\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8107 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8282\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8088 - val_loss: 0.2392 - val_binary_accuracy: 0.6780 - val_AUC: 0.8171\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8086 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8221\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8088 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8296\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8118 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8222\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8076 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8174\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8082 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8221\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8110 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8281\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8098 - val_loss: 0.2391 - val_binary_accuracy: 0.6810 - val_AUC: 0.8177\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8082 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8250\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2389 - binary_accuracy: 0.6960 - AUC: 0.8121 - val_loss: 0.2391 - val_binary_accuracy: 0.6900 - val_AUC: 0.8284\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8112 - val_loss: 0.2392 - val_binary_accuracy: 0.6820 - val_AUC: 0.8186\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8075 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8254\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6890 - AUC: 0.8052 - val_loss: 0.2391 - val_binary_accuracy: 0.6800 - val_AUC: 0.8175\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2389 - binary_accuracy: 0.6960 - AUC: 0.8102 - val_loss: 0.2391 - val_binary_accuracy: 0.6900 - val_AUC: 0.8292\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6900 - AUC: 0.8051 - val_loss: 0.2392 - val_binary_accuracy: 0.6800 - val_AUC: 0.8177\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8081 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8290\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8092 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8220\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6950 - AUC: 0.8112 - val_loss: 0.2391 - val_binary_accuracy: 0.6880 - val_AUC: 0.8300\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8104 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8262\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8110 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8292\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8104 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8207\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8084 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8237\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8092 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8286\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8054 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8221\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8081 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8221\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8104 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8292\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6950 - AUC: 0.8111 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8291\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8113 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8282\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 15s 15ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8092 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8282\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 15s 15ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8081 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8229\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8123 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8287\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8116 - val_loss: 0.2391 - val_binary_accuracy: 0.6850 - val_AUC: 0.8273\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8069 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8252\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6960 - AUC: 0.8126 - val_loss: 0.2391 - val_binary_accuracy: 0.6900 - val_AUC: 0.8300\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8051 - val_loss: 0.2392 - val_binary_accuracy: 0.6800 - val_AUC: 0.8169\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8071 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8300\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8105 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8281\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8102 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8220\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6930 - AUC: 0.8104 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8279\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8097 - val_loss: 0.2391 - val_binary_accuracy: 0.6830 - val_AUC: 0.8243\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8066 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8176\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8081 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8294\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8069 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8243\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6950 - AUC: 0.8145 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8276\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6950 - AUC: 0.8130 - val_loss: 0.2391 - val_binary_accuracy: 0.6900 - val_AUC: 0.8298\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8126 - val_loss: 0.2391 - val_binary_accuracy: 0.6840 - val_AUC: 0.8265\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6910 - AUC: 0.8096 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8291\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8065 - val_loss: 0.2391 - val_binary_accuracy: 0.6870 - val_AUC: 0.8287\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6940 - AUC: 0.8104 - val_loss: 0.2391 - val_binary_accuracy: 0.6860 - val_AUC: 0.8292\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 14s 14ms/sample - loss: 0.2388 - binary_accuracy: 0.6920 - AUC: 0.8074 - val_loss: 0.2391 - val_binary_accuracy: 0.6820 - val_AUC: 0.8184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-08-09 14:51:15,654 [MainThread  ][INFO ]  ######## Training Ends ########\n",
            "2020-08-09 14:51:15,663 [MainThread  ][INFO ]  Model weights: \n",
            "[ 8.8740838e-01  5.6962819e+00 -5.5508539e-02  4.7184024e+00\n",
            "  4.8664904e+00  3.1296399e-01  4.6454296e+00  3.6543555e+00\n",
            "  1.6109911e+00  4.7911825e+00  3.5413194e-01  2.6348860e+00\n",
            "  5.9223952e+00  2.6487622e+00  4.7125115e+00  1.2048173e+00\n",
            "  2.5141828e+00  2.8927550e+00  4.4965205e+00  5.4954624e+00\n",
            "  9.9750727e-01  5.9994340e+00 -3.4908304e-04  5.1231112e+00\n",
            "  2.6524866e+00  4.7019234e+00  1.7384317e+00  8.2696658e-01\n",
            "  3.9223645e+00  4.4099178e+00]\n",
            "Converting circuits to tensors...\n",
            "2020-08-09 14:51:18,260 [MainThread  ][INFO ]  ######## Test Begins ########\n",
            "2020-08-09 14:51:18,261 [MainThread  ][INFO ]  Number of samples for Testing: 1000\n",
            "2020-08-09 14:51:18,264 [MainThread  ][INFO ]  Number of Epochs: 1\n",
            "2020-08-09 14:51:18,266 [MainThread  ][INFO ]  Batch Size: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2396 - binary_accuracy: 0.6700 - AUC: 0.8056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-08-09 14:51:19,479 [MainThread  ][INFO ]  *Note: for tensorflow version < 2.3.0, the test results are not loaded into logs\n",
            "2020-08-09 14:51:19,483 [MainThread  ][INFO ]  ######## Test Ends ########\n",
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvyi4s6WnmwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16871843-3400-4332-be7b-5b7fffcbf129"
      },
      "source": [
        "#print out the content of the log file\n",
        "import glob\n",
        "logfile = glob.glob('logs/*.log')[0]\n",
        "#check the log file\n",
        "print(open(logfile, 'r').read())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-09 14:27:23,143 [MainThread  ][INFO ]  ######## Executing VQC with the following attributes ########\n",
            "2020-08-09 14:27:23,144 [MainThread  ][INFO ]  Feature Dimension: 5\n",
            "2020-08-09 14:27:23,147 [MainThread  ][INFO ]  Number of Qubits: 6\n",
            "2020-08-09 14:27:23,149 [MainThread  ][INFO ]  Qubit Layout: [cirq.GridQubit(-1, -1), cirq.GridQubit(0, 0), cirq.GridQubit(0, 1), cirq.GridQubit(0, 2), cirq.GridQubit(0, 3), cirq.GridQubit(0, 4)]\n",
            "2020-08-09 14:27:23,151 [MainThread  ][INFO ]  Encoding Circuit: FirstOrderExpansion\n",
            "2020-08-09 14:27:23,153 [MainThread  ][INFO ]  Encoding Map: self_product\n",
            "2020-08-09 14:27:23,157 [MainThread  ][INFO ]  Variational Circuit: EfficientSU2\n",
            "2020-08-09 14:27:23,159 [MainThread  ][INFO ]  Circuit Parameters: ['θ_0', 'θ_1', 'θ_10', 'θ_11', 'θ_12', 'θ_13', 'θ_14', 'θ_15', 'θ_16', 'θ_17', 'θ_18', 'θ_19', 'θ_2', 'θ_20', 'θ_21', 'θ_22', 'θ_23', 'θ_24', 'θ_25', 'θ_26', 'θ_27', 'θ_28', 'θ_29', 'θ_3', 'θ_4', 'θ_5', 'θ_6', 'θ_7', 'θ_8', 'θ_9']\n",
            "2020-08-09 14:27:23,161 [MainThread  ][INFO ]  Number of Parameters: 30\n",
            "2020-08-09 14:27:23,163 [MainThread  ][INFO ]  Optimizer: Adam\n",
            "2020-08-09 14:27:23,164 [MainThread  ][INFO ]  Metrics: ['binary_accuracy', 'AUC']\n",
            "2020-08-09 14:27:23,167 [MainThread  ][INFO ]  Loss Function: ['mean_squared_error']\n",
            "2020-08-09 14:27:23,168 [MainThread  ][INFO ]  Activation Function: sigmoid\n",
            "2020-08-09 14:27:23,170 [MainThread  ][INFO ]  Training Size: 1000\n",
            "2020-08-09 14:27:23,171 [MainThread  ][INFO ]  Validation Size: 1000\n",
            "2020-08-09 14:27:23,172 [MainThread  ][INFO ]  Test Size: 1000\n",
            "2020-08-09 14:27:23,174 [MainThread  ][INFO ]  Batch Size: 64\n",
            "2020-08-09 14:27:23,176 [MainThread  ][INFO ]  Number of Epochs: 100\n",
            "2020-08-09 14:27:23,191 [MainThread  ][DEBUG]  Circuit Diagram for Encoding Circuit:\n",
            "(0, 0): ───H───Rz(pi*x_0)───H───Rz(pi*x_0)───\n",
            "\n",
            "(0, 1): ───H───Rz(pi*x_1)───H───Rz(pi*x_1)───\n",
            "\n",
            "(0, 2): ───H───Rz(pi*x_2)───H───Rz(pi*x_2)───\n",
            "\n",
            "(0, 3): ───H───Rz(pi*x_3)───H───Rz(pi*x_3)───\n",
            "\n",
            "(0, 4): ───H───Rz(pi*x_4)───H───Rz(pi*x_4)───\n",
            "2020-08-09 14:27:23,222 [MainThread  ][DEBUG]  Circuit Diagram for Variational Circuit:\n",
            "                                             ┌──┐       ┌──┐                                             ┌──┐       ┌──┐\n",
            "(-1, -1): ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────XX──────────XX──────────XX──────────XX──────────XX──────────\n",
            "                                                                                                                                          │           │           │           │           │\n",
            "(0, 0): ─────Ry(θ_0)───Rz(θ_5)───@───@───@────@────────────────────────Ry(θ_10)───Rz(θ_15)───@───@───@────@────────────────────Rz(θ_20)───XX^(θ_25)───┼───────────┼───────────┼───────────┼───────────\n",
            "                                 │   │   │    │                                              │   │   │    │                                           │           │           │           │\n",
            "(0, 1): ─────Ry(θ_1)───Rz(θ_6)───X───┼───┼────┼@────@────@─────────────Ry(θ_11)───Rz(θ_16)───X───┼───┼────┼@────@────@─────────Rz(θ_21)───────────────XX^(θ_26)───┼───────────┼───────────┼───────────\n",
            "                                     │   │    ││    │    │                                       │   │    ││    │    │                                            │           │           │\n",
            "(0, 2): ─────Ry(θ_2)───Rz(θ_7)───────X───┼────┼X────┼────┼@────@───────Ry(θ_12)───Rz(θ_17)───────X───┼────┼X────┼────┼@────@───Rz(θ_22)───────────────────────────XX^(θ_27)───┼───────────┼───────────\n",
            "                                         │    │     │    ││    │                                     │    │     │    ││    │                                                  │           │\n",
            "(0, 3): ─────Ry(θ_3)───Rz(θ_8)───────────X────┼─────X────┼X────┼───@───Ry(θ_13)───Rz(θ_18)───────────X────┼─────X────┼X────┼───@──────────Rz(θ_23)────────────────────────────XX^(θ_28)───┼───────────\n",
            "                                              │          │     │   │                                      │          │     │   │                                                          │\n",
            "(0, 4): ─────Ry(θ_4)───Rz(θ_9)────────────────X──────────X─────X───X───Ry(θ_14)───Rz(θ_19)────────────────X──────────X─────X───X──────────Rz(θ_24)────────────────────────────────────────XX^(θ_29)───\n",
            "                                             └──┘       └──┘                                             └──┘       └──┘\n",
            "2020-08-09 14:27:23,222 [MainThread  ][INFO ]  ######## Training Begins ########\n",
            "2020-08-09 14:27:23,223 [MainThread  ][INFO ]  Number of samples for Training: 1000\n",
            "2020-08-09 14:27:23,227 [MainThread  ][INFO ]  Number of Epochs: 100\n",
            "2020-08-09 14:27:23,229 [MainThread  ][INFO ]  Batch Size: 64\n",
            "2020-08-09 14:27:39,294 [MainThread  ][DEBUG]  ######## Epoch 0 ########\n",
            "2020-08-09 14:27:39,294 [MainThread  ][DEBUG]  loss: 0.24769382119178773\n",
            "2020-08-09 14:27:39,294 [MainThread  ][DEBUG]  binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:27:39,294 [MainThread  ][DEBUG]  AUC: 0.7132959365844727\n",
            "2020-08-09 14:27:39,294 [MainThread  ][DEBUG]  val_loss: 0.2456883661746979\n",
            "2020-08-09 14:27:39,294 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6359999775886536\n",
            "2020-08-09 14:27:39,294 [MainThread  ][DEBUG]  val_AUC: 0.7802680134773254\n",
            "2020-08-09 14:27:53,312 [MainThread  ][DEBUG]  ######## Epoch 1 ########\n",
            "2020-08-09 14:27:53,312 [MainThread  ][DEBUG]  loss: 0.2438567179441452\n",
            "2020-08-09 14:27:53,312 [MainThread  ][DEBUG]  binary_accuracy: 0.6460000276565552\n",
            "2020-08-09 14:27:53,312 [MainThread  ][DEBUG]  AUC: 0.7823500037193298\n",
            "2020-08-09 14:27:53,312 [MainThread  ][DEBUG]  val_loss: 0.24293179893493652\n",
            "2020-08-09 14:27:53,312 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6209999918937683\n",
            "2020-08-09 14:27:53,312 [MainThread  ][DEBUG]  val_AUC: 0.7908740043640137\n",
            "2020-08-09 14:28:07,731 [MainThread  ][DEBUG]  ######## Epoch 2 ########\n",
            "2020-08-09 14:28:07,732 [MainThread  ][DEBUG]  loss: 0.24175145149230956\n",
            "2020-08-09 14:28:07,732 [MainThread  ][DEBUG]  binary_accuracy: 0.6359999775886536\n",
            "2020-08-09 14:28:07,732 [MainThread  ][DEBUG]  AUC: 0.8008360266685486\n",
            "2020-08-09 14:28:07,732 [MainThread  ][DEBUG]  val_loss: 0.24124643898010253\n",
            "2020-08-09 14:28:07,732 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6349999904632568\n",
            "2020-08-09 14:28:07,732 [MainThread  ][DEBUG]  val_AUC: 0.82423996925354\n",
            "2020-08-09 14:28:21,818 [MainThread  ][DEBUG]  ######## Epoch 3 ########\n",
            "2020-08-09 14:28:21,818 [MainThread  ][DEBUG]  loss: 0.24039606094360352\n",
            "2020-08-09 14:28:21,818 [MainThread  ][DEBUG]  binary_accuracy: 0.6690000295639038\n",
            "2020-08-09 14:28:21,818 [MainThread  ][DEBUG]  AUC: 0.825659990310669\n",
            "2020-08-09 14:28:21,818 [MainThread  ][DEBUG]  val_loss: 0.24023877227306367\n",
            "2020-08-09 14:28:21,818 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6570000052452087\n",
            "2020-08-09 14:28:21,818 [MainThread  ][DEBUG]  val_AUC: 0.8334959745407104\n",
            "2020-08-09 14:28:35,971 [MainThread  ][DEBUG]  ######## Epoch 4 ########\n",
            "2020-08-09 14:28:35,971 [MainThread  ][DEBUG]  loss: 0.23951288592815398\n",
            "2020-08-09 14:28:35,971 [MainThread  ][DEBUG]  binary_accuracy: 0.671999990940094\n",
            "2020-08-09 14:28:35,972 [MainThread  ][DEBUG]  AUC: 0.8312000036239624\n",
            "2020-08-09 14:28:35,972 [MainThread  ][DEBUG]  val_loss: 0.239640572309494\n",
            "2020-08-09 14:28:35,972 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6589999794960022\n",
            "2020-08-09 14:28:35,972 [MainThread  ][DEBUG]  val_AUC: 0.8332940340042114\n",
            "2020-08-09 14:28:50,099 [MainThread  ][DEBUG]  ######## Epoch 5 ########\n",
            "2020-08-09 14:28:50,099 [MainThread  ][DEBUG]  loss: 0.23907811570167542\n",
            "2020-08-09 14:28:50,099 [MainThread  ][DEBUG]  binary_accuracy: 0.6779999732971191\n",
            "2020-08-09 14:28:50,099 [MainThread  ][DEBUG]  AUC: 0.824004054069519\n",
            "2020-08-09 14:28:50,099 [MainThread  ][DEBUG]  val_loss: 0.23923465085029602\n",
            "2020-08-09 14:28:50,099 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6700000166893005\n",
            "2020-08-09 14:28:50,099 [MainThread  ][DEBUG]  val_AUC: 0.8356980085372925\n",
            "2020-08-09 14:29:04,245 [MainThread  ][DEBUG]  ######## Epoch 6 ########\n",
            "2020-08-09 14:29:04,245 [MainThread  ][DEBUG]  loss: 0.2388639793395996\n",
            "2020-08-09 14:29:04,245 [MainThread  ][DEBUG]  binary_accuracy: 0.6899999976158142\n",
            "2020-08-09 14:29:04,245 [MainThread  ][DEBUG]  AUC: 0.8220880031585693\n",
            "2020-08-09 14:29:04,245 [MainThread  ][DEBUG]  val_loss: 0.23914411449432374\n",
            "2020-08-09 14:29:04,245 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6779999732971191\n",
            "2020-08-09 14:29:04,245 [MainThread  ][DEBUG]  val_AUC: 0.828510046005249\n",
            "2020-08-09 14:29:18,411 [MainThread  ][DEBUG]  ######## Epoch 7 ########\n",
            "2020-08-09 14:29:18,411 [MainThread  ][DEBUG]  loss: 0.23881413543224334\n",
            "2020-08-09 14:29:18,411 [MainThread  ][DEBUG]  binary_accuracy: 0.6899999976158142\n",
            "2020-08-09 14:29:18,411 [MainThread  ][DEBUG]  AUC: 0.8119080066680908\n",
            "2020-08-09 14:29:18,411 [MainThread  ][DEBUG]  val_loss: 0.23917135071754456\n",
            "2020-08-09 14:29:18,411 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6729999780654907\n",
            "2020-08-09 14:29:18,411 [MainThread  ][DEBUG]  val_AUC: 0.8244360089302063\n",
            "2020-08-09 14:29:32,533 [MainThread  ][DEBUG]  ######## Epoch 8 ########\n",
            "2020-08-09 14:29:32,534 [MainThread  ][DEBUG]  loss: 0.2388055078983307\n",
            "2020-08-09 14:29:32,534 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:29:32,534 [MainThread  ][DEBUG]  AUC: 0.8037059307098389\n",
            "2020-08-09 14:29:32,534 [MainThread  ][DEBUG]  val_loss: 0.23912809264659882\n",
            "2020-08-09 14:29:32,534 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:29:32,534 [MainThread  ][DEBUG]  val_AUC: 0.8189700245857239\n",
            "2020-08-09 14:29:46,744 [MainThread  ][DEBUG]  ######## Epoch 9 ########\n",
            "2020-08-09 14:29:46,745 [MainThread  ][DEBUG]  loss: 0.2388449364900589\n",
            "2020-08-09 14:29:46,745 [MainThread  ][DEBUG]  binary_accuracy: 0.6890000104904175\n",
            "2020-08-09 14:29:46,745 [MainThread  ][DEBUG]  AUC: 0.8057519197463989\n",
            "2020-08-09 14:29:46,745 [MainThread  ][DEBUG]  val_loss: 0.23911425137519837\n",
            "2020-08-09 14:29:46,745 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:29:46,745 [MainThread  ][DEBUG]  val_AUC: 0.8284299969673157\n",
            "2020-08-09 14:30:00,895 [MainThread  ][DEBUG]  ######## Epoch 10 ########\n",
            "2020-08-09 14:30:00,895 [MainThread  ][DEBUG]  loss: 0.23882871556282043\n",
            "2020-08-09 14:30:00,895 [MainThread  ][DEBUG]  binary_accuracy: 0.6970000267028809\n",
            "2020-08-09 14:30:00,895 [MainThread  ][DEBUG]  AUC: 0.8124200105667114\n",
            "2020-08-09 14:30:00,895 [MainThread  ][DEBUG]  val_loss: 0.23910544753074647\n",
            "2020-08-09 14:30:00,895 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6890000104904175\n",
            "2020-08-09 14:30:00,895 [MainThread  ][DEBUG]  val_AUC: 0.8291240334510803\n",
            "2020-08-09 14:30:15,243 [MainThread  ][DEBUG]  ######## Epoch 11 ########\n",
            "2020-08-09 14:30:15,244 [MainThread  ][DEBUG]  loss: 0.23880467236042022\n",
            "2020-08-09 14:30:15,244 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:30:15,244 [MainThread  ][DEBUG]  AUC: 0.8131740093231201\n",
            "2020-08-09 14:30:15,244 [MainThread  ][DEBUG]  val_loss: 0.2391307772397995\n",
            "2020-08-09 14:30:15,244 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:30:15,244 [MainThread  ][DEBUG]  val_AUC: 0.8299059271812439\n",
            "2020-08-09 14:30:29,478 [MainThread  ][DEBUG]  ######## Epoch 12 ########\n",
            "2020-08-09 14:30:29,478 [MainThread  ][DEBUG]  loss: 0.2388093340396881\n",
            "2020-08-09 14:30:29,478 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:30:29,478 [MainThread  ][DEBUG]  AUC: 0.8097360730171204\n",
            "2020-08-09 14:30:29,478 [MainThread  ][DEBUG]  val_loss: 0.2391212933063507\n",
            "2020-08-09 14:30:29,478 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:30:29,478 [MainThread  ][DEBUG]  val_AUC: 0.8251199722290039\n",
            "2020-08-09 14:30:43,698 [MainThread  ][DEBUG]  ######## Epoch 13 ########\n",
            "2020-08-09 14:30:43,698 [MainThread  ][DEBUG]  loss: 0.23882628428936004\n",
            "2020-08-09 14:30:43,698 [MainThread  ][DEBUG]  binary_accuracy: 0.6959999799728394\n",
            "2020-08-09 14:30:43,698 [MainThread  ][DEBUG]  AUC: 0.8119900822639465\n",
            "2020-08-09 14:30:43,698 [MainThread  ][DEBUG]  val_loss: 0.2391159029006958\n",
            "2020-08-09 14:30:43,698 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:30:43,699 [MainThread  ][DEBUG]  val_AUC: 0.8289099335670471\n",
            "2020-08-09 14:30:57,917 [MainThread  ][DEBUG]  ######## Epoch 14 ########\n",
            "2020-08-09 14:30:57,918 [MainThread  ][DEBUG]  loss: 0.23883983063697814\n",
            "2020-08-09 14:30:57,918 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:30:57,918 [MainThread  ][DEBUG]  AUC: 0.8072800636291504\n",
            "2020-08-09 14:30:57,918 [MainThread  ][DEBUG]  val_loss: 0.23914854717254638\n",
            "2020-08-09 14:30:57,918 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6800000071525574\n",
            "2020-08-09 14:30:57,918 [MainThread  ][DEBUG]  val_AUC: 0.817732036113739\n",
            "2020-08-09 14:31:12,137 [MainThread  ][DEBUG]  ######## Epoch 15 ########\n",
            "2020-08-09 14:31:12,138 [MainThread  ][DEBUG]  loss: 0.23881123530864715\n",
            "2020-08-09 14:31:12,138 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:31:12,138 [MainThread  ][DEBUG]  AUC: 0.8081440329551697\n",
            "2020-08-09 14:31:12,138 [MainThread  ][DEBUG]  val_loss: 0.23911837017536164\n",
            "2020-08-09 14:31:12,138 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:31:12,138 [MainThread  ][DEBUG]  val_AUC: 0.8253700137138367\n",
            "2020-08-09 14:31:26,395 [MainThread  ][DEBUG]  ######## Epoch 16 ########\n",
            "2020-08-09 14:31:26,395 [MainThread  ][DEBUG]  loss: 0.23880673575401307\n",
            "2020-08-09 14:31:26,395 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:31:26,395 [MainThread  ][DEBUG]  AUC: 0.8097699880599976\n",
            "2020-08-09 14:31:26,395 [MainThread  ][DEBUG]  val_loss: 0.23912431800365447\n",
            "2020-08-09 14:31:26,395 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:31:26,395 [MainThread  ][DEBUG]  val_AUC: 0.8245900273323059\n",
            "2020-08-09 14:31:40,690 [MainThread  ][DEBUG]  ######## Epoch 17 ########\n",
            "2020-08-09 14:31:40,690 [MainThread  ][DEBUG]  loss: 0.23880900490283966\n",
            "2020-08-09 14:31:40,691 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:31:40,691 [MainThread  ][DEBUG]  AUC: 0.8086540102958679\n",
            "2020-08-09 14:31:40,691 [MainThread  ][DEBUG]  val_loss: 0.239114768743515\n",
            "2020-08-09 14:31:40,691 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:31:40,691 [MainThread  ][DEBUG]  val_AUC: 0.8300119638442993\n",
            "2020-08-09 14:31:54,921 [MainThread  ][DEBUG]  ######## Epoch 18 ########\n",
            "2020-08-09 14:31:54,922 [MainThread  ][DEBUG]  loss: 0.23882689201831817\n",
            "2020-08-09 14:31:54,922 [MainThread  ][DEBUG]  binary_accuracy: 0.6890000104904175\n",
            "2020-08-09 14:31:54,922 [MainThread  ][DEBUG]  AUC: 0.8075479865074158\n",
            "2020-08-09 14:31:54,922 [MainThread  ][DEBUG]  val_loss: 0.23914543163776397\n",
            "2020-08-09 14:31:54,922 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6790000200271606\n",
            "2020-08-09 14:31:54,922 [MainThread  ][DEBUG]  val_AUC: 0.8172879815101624\n",
            "2020-08-09 14:32:09,170 [MainThread  ][DEBUG]  ######## Epoch 19 ########\n",
            "2020-08-09 14:32:09,170 [MainThread  ][DEBUG]  loss: 0.23880909609794618\n",
            "2020-08-09 14:32:09,170 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:32:09,170 [MainThread  ][DEBUG]  AUC: 0.8058439493179321\n",
            "2020-08-09 14:32:09,170 [MainThread  ][DEBUG]  val_loss: 0.2391157282590866\n",
            "2020-08-09 14:32:09,171 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:32:09,171 [MainThread  ][DEBUG]  val_AUC: 0.828373908996582\n",
            "2020-08-09 14:32:23,494 [MainThread  ][DEBUG]  ######## Epoch 20 ########\n",
            "2020-08-09 14:32:23,495 [MainThread  ][DEBUG]  loss: 0.23880413353443145\n",
            "2020-08-09 14:32:23,495 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:32:23,495 [MainThread  ][DEBUG]  AUC: 0.8120061159133911\n",
            "2020-08-09 14:32:23,495 [MainThread  ][DEBUG]  val_loss: 0.23911261069774628\n",
            "2020-08-09 14:32:23,495 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:32:23,495 [MainThread  ][DEBUG]  val_AUC: 0.8284119963645935\n",
            "2020-08-09 14:32:37,791 [MainThread  ][DEBUG]  ######## Epoch 21 ########\n",
            "2020-08-09 14:32:37,791 [MainThread  ][DEBUG]  loss: 0.23880574905872345\n",
            "2020-08-09 14:32:37,791 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:32:37,791 [MainThread  ][DEBUG]  AUC: 0.8113219738006592\n",
            "2020-08-09 14:32:37,791 [MainThread  ][DEBUG]  val_loss: 0.23913770389556885\n",
            "2020-08-09 14:32:37,791 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:32:37,791 [MainThread  ][DEBUG]  val_AUC: 0.8206479549407959\n",
            "2020-08-09 14:32:52,178 [MainThread  ][DEBUG]  ######## Epoch 22 ########\n",
            "2020-08-09 14:32:52,178 [MainThread  ][DEBUG]  loss: 0.23880424296855926\n",
            "2020-08-09 14:32:52,178 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:32:52,179 [MainThread  ][DEBUG]  AUC: 0.8084219694137573\n",
            "2020-08-09 14:32:52,179 [MainThread  ][DEBUG]  val_loss: 0.2391094034910202\n",
            "2020-08-09 14:32:52,179 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:32:52,179 [MainThread  ][DEBUG]  val_AUC: 0.8279980421066284\n",
            "2020-08-09 14:33:06,513 [MainThread  ][DEBUG]  ######## Epoch 23 ########\n",
            "2020-08-09 14:33:06,513 [MainThread  ][DEBUG]  loss: 0.2388210029602051\n",
            "2020-08-09 14:33:06,513 [MainThread  ][DEBUG]  binary_accuracy: 0.6959999799728394\n",
            "2020-08-09 14:33:06,513 [MainThread  ][DEBUG]  AUC: 0.8127140998840332\n",
            "2020-08-09 14:33:06,513 [MainThread  ][DEBUG]  val_loss: 0.23911125266551972\n",
            "2020-08-09 14:33:06,513 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6880000233650208\n",
            "2020-08-09 14:33:06,513 [MainThread  ][DEBUG]  val_AUC: 0.8301839828491211\n",
            "2020-08-09 14:33:20,747 [MainThread  ][DEBUG]  ######## Epoch 24 ########\n",
            "2020-08-09 14:33:20,747 [MainThread  ][DEBUG]  loss: 0.23880316853523254\n",
            "2020-08-09 14:33:20,747 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:33:20,747 [MainThread  ][DEBUG]  AUC: 0.8095319867134094\n",
            "2020-08-09 14:33:20,747 [MainThread  ][DEBUG]  val_loss: 0.23914091885089875\n",
            "2020-08-09 14:33:20,747 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:33:20,747 [MainThread  ][DEBUG]  val_AUC: 0.8206640481948853\n",
            "2020-08-09 14:33:35,019 [MainThread  ][DEBUG]  ######## Epoch 25 ########\n",
            "2020-08-09 14:33:35,020 [MainThread  ][DEBUG]  loss: 0.23881815218925476\n",
            "2020-08-09 14:33:35,020 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:33:35,020 [MainThread  ][DEBUG]  AUC: 0.8043760061264038\n",
            "2020-08-09 14:33:35,020 [MainThread  ][DEBUG]  val_loss: 0.2391329925060272\n",
            "2020-08-09 14:33:35,020 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6800000071525574\n",
            "2020-08-09 14:33:35,020 [MainThread  ][DEBUG]  val_AUC: 0.8180639743804932\n",
            "2020-08-09 14:33:49,238 [MainThread  ][DEBUG]  ######## Epoch 26 ########\n",
            "2020-08-09 14:33:49,238 [MainThread  ][DEBUG]  loss: 0.23883540737628936\n",
            "2020-08-09 14:33:49,238 [MainThread  ][DEBUG]  binary_accuracy: 0.6949999928474426\n",
            "2020-08-09 14:33:49,238 [MainThread  ][DEBUG]  AUC: 0.8106839656829834\n",
            "2020-08-09 14:33:49,238 [MainThread  ][DEBUG]  val_loss: 0.23911796295642854\n",
            "2020-08-09 14:33:49,238 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:33:49,238 [MainThread  ][DEBUG]  val_AUC: 0.8300179839134216\n",
            "2020-08-09 14:34:03,483 [MainThread  ][DEBUG]  ######## Epoch 27 ########\n",
            "2020-08-09 14:34:03,483 [MainThread  ][DEBUG]  loss: 0.23881191730499268\n",
            "2020-08-09 14:34:03,483 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:34:03,483 [MainThread  ][DEBUG]  AUC: 0.8078040480613708\n",
            "2020-08-09 14:34:03,483 [MainThread  ][DEBUG]  val_loss: 0.23915413069725036\n",
            "2020-08-09 14:34:03,483 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6779999732971191\n",
            "2020-08-09 14:34:03,484 [MainThread  ][DEBUG]  val_AUC: 0.8153140544891357\n",
            "2020-08-09 14:34:17,780 [MainThread  ][DEBUG]  ######## Epoch 28 ########\n",
            "2020-08-09 14:34:17,780 [MainThread  ][DEBUG]  loss: 0.23881535065174103\n",
            "2020-08-09 14:34:17,780 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:34:17,780 [MainThread  ][DEBUG]  AUC: 0.8079020977020264\n",
            "2020-08-09 14:34:17,780 [MainThread  ][DEBUG]  val_loss: 0.239113933801651\n",
            "2020-08-09 14:34:17,781 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:34:17,781 [MainThread  ][DEBUG]  val_AUC: 0.8300239443778992\n",
            "2020-08-09 14:34:32,073 [MainThread  ][DEBUG]  ######## Epoch 29 ########\n",
            "2020-08-09 14:34:32,073 [MainThread  ][DEBUG]  loss: 0.238809876203537\n",
            "2020-08-09 14:34:32,073 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:34:32,074 [MainThread  ][DEBUG]  AUC: 0.8075600266456604\n",
            "2020-08-09 14:34:32,074 [MainThread  ][DEBUG]  val_loss: 0.23915442955493926\n",
            "2020-08-09 14:34:32,074 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6779999732971191\n",
            "2020-08-09 14:34:32,074 [MainThread  ][DEBUG]  val_AUC: 0.8164700269699097\n",
            "2020-08-09 14:34:46,347 [MainThread  ][DEBUG]  ######## Epoch 30 ########\n",
            "2020-08-09 14:34:46,347 [MainThread  ][DEBUG]  loss: 0.23882390856742858\n",
            "2020-08-09 14:34:46,347 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:34:46,347 [MainThread  ][DEBUG]  AUC: 0.8092899918556213\n",
            "2020-08-09 14:34:46,347 [MainThread  ][DEBUG]  val_loss: 0.23912940096855165\n",
            "2020-08-09 14:34:46,347 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:34:46,347 [MainThread  ][DEBUG]  val_AUC: 0.825141966342926\n",
            "2020-08-09 14:35:00,657 [MainThread  ][DEBUG]  ######## Epoch 31 ########\n",
            "2020-08-09 14:35:00,658 [MainThread  ][DEBUG]  loss: 0.2388132563829422\n",
            "2020-08-09 14:35:00,658 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:35:00,658 [MainThread  ][DEBUG]  AUC: 0.8058421015739441\n",
            "2020-08-09 14:35:00,658 [MainThread  ][DEBUG]  val_loss: 0.23911721587181092\n",
            "2020-08-09 14:35:00,658 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:35:00,658 [MainThread  ][DEBUG]  val_AUC: 0.8258019685745239\n",
            "2020-08-09 14:35:15,002 [MainThread  ][DEBUG]  ######## Epoch 32 ########\n",
            "2020-08-09 14:35:15,002 [MainThread  ][DEBUG]  loss: 0.23880396723747255\n",
            "2020-08-09 14:35:15,002 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:35:15,002 [MainThread  ][DEBUG]  AUC: 0.8091560006141663\n",
            "2020-08-09 14:35:15,002 [MainThread  ][DEBUG]  val_loss: 0.23912533962726593\n",
            "2020-08-09 14:35:15,002 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:35:15,002 [MainThread  ][DEBUG]  val_AUC: 0.8238600492477417\n",
            "2020-08-09 14:35:29,377 [MainThread  ][DEBUG]  ######## Epoch 33 ########\n",
            "2020-08-09 14:35:29,377 [MainThread  ][DEBUG]  loss: 0.23880968070030212\n",
            "2020-08-09 14:35:29,377 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:35:29,377 [MainThread  ][DEBUG]  AUC: 0.8072640299797058\n",
            "2020-08-09 14:35:29,377 [MainThread  ][DEBUG]  val_loss: 0.23911446368694306\n",
            "2020-08-09 14:35:29,377 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:35:29,377 [MainThread  ][DEBUG]  val_AUC: 0.8300119638442993\n",
            "2020-08-09 14:35:43,692 [MainThread  ][DEBUG]  ######## Epoch 34 ########\n",
            "2020-08-09 14:35:43,692 [MainThread  ][DEBUG]  loss: 0.23881271636486054\n",
            "2020-08-09 14:35:43,692 [MainThread  ][DEBUG]  binary_accuracy: 0.6899999976158142\n",
            "2020-08-09 14:35:43,692 [MainThread  ][DEBUG]  AUC: 0.8075639605522156\n",
            "2020-08-09 14:35:43,692 [MainThread  ][DEBUG]  val_loss: 0.23913339412212373\n",
            "2020-08-09 14:35:43,692 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:35:43,692 [MainThread  ][DEBUG]  val_AUC: 0.8173980116844177\n",
            "2020-08-09 14:35:57,939 [MainThread  ][DEBUG]  ######## Epoch 35 ########\n",
            "2020-08-09 14:35:57,940 [MainThread  ][DEBUG]  loss: 0.2388382260799408\n",
            "2020-08-09 14:35:57,940 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:35:57,940 [MainThread  ][DEBUG]  AUC: 0.8096059560775757\n",
            "2020-08-09 14:35:57,940 [MainThread  ][DEBUG]  val_loss: 0.23911877655982972\n",
            "2020-08-09 14:35:57,940 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:35:57,940 [MainThread  ][DEBUG]  val_AUC: 0.8290099501609802\n",
            "2020-08-09 14:36:13,527 [MainThread  ][DEBUG]  ######## Epoch 36 ########\n",
            "2020-08-09 14:36:13,527 [MainThread  ][DEBUG]  loss: 0.23882824420928955\n",
            "2020-08-09 14:36:13,527 [MainThread  ][DEBUG]  binary_accuracy: 0.6959999799728394\n",
            "2020-08-09 14:36:13,527 [MainThread  ][DEBUG]  AUC: 0.8101379871368408\n",
            "2020-08-09 14:36:13,527 [MainThread  ][DEBUG]  val_loss: 0.2391228702068329\n",
            "2020-08-09 14:36:13,527 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:36:13,527 [MainThread  ][DEBUG]  val_AUC: 0.8285679817199707\n",
            "2020-08-09 14:36:27,827 [MainThread  ][DEBUG]  ######## Epoch 37 ########\n",
            "2020-08-09 14:36:27,827 [MainThread  ][DEBUG]  loss: 0.2388041160106659\n",
            "2020-08-09 14:36:27,827 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:36:27,827 [MainThread  ][DEBUG]  AUC: 0.806041955947876\n",
            "2020-08-09 14:36:27,827 [MainThread  ][DEBUG]  val_loss: 0.23914275550842284\n",
            "2020-08-09 14:36:27,827 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:36:27,827 [MainThread  ][DEBUG]  val_AUC: 0.817840039730072\n",
            "2020-08-09 14:36:42,155 [MainThread  ][DEBUG]  ######## Epoch 38 ########\n",
            "2020-08-09 14:36:42,156 [MainThread  ][DEBUG]  loss: 0.238806786775589\n",
            "2020-08-09 14:36:42,156 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:36:42,156 [MainThread  ][DEBUG]  AUC: 0.8096179962158203\n",
            "2020-08-09 14:36:42,156 [MainThread  ][DEBUG]  val_loss: 0.23911840891838074\n",
            "2020-08-09 14:36:42,156 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:36:42,156 [MainThread  ][DEBUG]  val_AUC: 0.8261579871177673\n",
            "2020-08-09 14:36:56,461 [MainThread  ][DEBUG]  ######## Epoch 39 ########\n",
            "2020-08-09 14:36:56,462 [MainThread  ][DEBUG]  loss: 0.2388119419813156\n",
            "2020-08-09 14:36:56,462 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:36:56,462 [MainThread  ][DEBUG]  AUC: 0.8076340556144714\n",
            "2020-08-09 14:36:56,462 [MainThread  ][DEBUG]  val_loss: 0.23914036297798158\n",
            "2020-08-09 14:36:56,462 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6809999942779541\n",
            "2020-08-09 14:36:56,462 [MainThread  ][DEBUG]  val_AUC: 0.8177859783172607\n",
            "2020-08-09 14:37:10,729 [MainThread  ][DEBUG]  ######## Epoch 40 ########\n",
            "2020-08-09 14:37:10,729 [MainThread  ][DEBUG]  loss: 0.23881364810466765\n",
            "2020-08-09 14:37:10,729 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:37:10,729 [MainThread  ][DEBUG]  AUC: 0.8075459599494934\n",
            "2020-08-09 14:37:10,729 [MainThread  ][DEBUG]  val_loss: 0.23911959052085877\n",
            "2020-08-09 14:37:10,729 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:37:10,729 [MainThread  ][DEBUG]  val_AUC: 0.8253520131111145\n",
            "2020-08-09 14:37:24,999 [MainThread  ][DEBUG]  ######## Epoch 41 ########\n",
            "2020-08-09 14:37:24,999 [MainThread  ][DEBUG]  loss: 0.23881575286388398\n",
            "2020-08-09 14:37:24,999 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:37:24,999 [MainThread  ][DEBUG]  AUC: 0.8064820170402527\n",
            "2020-08-09 14:37:24,999 [MainThread  ][DEBUG]  val_loss: 0.23913013064861297\n",
            "2020-08-09 14:37:25,000 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:37:25,000 [MainThread  ][DEBUG]  val_AUC: 0.8222619891166687\n",
            "2020-08-09 14:37:39,275 [MainThread  ][DEBUG]  ######## Epoch 42 ########\n",
            "2020-08-09 14:37:39,275 [MainThread  ][DEBUG]  loss: 0.23880565178394317\n",
            "2020-08-09 14:37:39,275 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:37:39,275 [MainThread  ][DEBUG]  AUC: 0.8092620372772217\n",
            "2020-08-09 14:37:39,275 [MainThread  ][DEBUG]  val_loss: 0.2391237906217575\n",
            "2020-08-09 14:37:39,275 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:37:39,275 [MainThread  ][DEBUG]  val_AUC: 0.8251140117645264\n",
            "2020-08-09 14:37:53,696 [MainThread  ][DEBUG]  ######## Epoch 43 ########\n",
            "2020-08-09 14:37:53,697 [MainThread  ][DEBUG]  loss: 0.23881817042827605\n",
            "2020-08-09 14:37:53,697 [MainThread  ][DEBUG]  binary_accuracy: 0.6890000104904175\n",
            "2020-08-09 14:37:53,697 [MainThread  ][DEBUG]  AUC: 0.8047159314155579\n",
            "2020-08-09 14:37:53,697 [MainThread  ][DEBUG]  val_loss: 0.2391280119419098\n",
            "2020-08-09 14:37:53,697 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:37:53,697 [MainThread  ][DEBUG]  val_AUC: 0.818120002746582\n",
            "2020-08-09 14:38:07,971 [MainThread  ][DEBUG]  ######## Epoch 44 ########\n",
            "2020-08-09 14:38:07,971 [MainThread  ][DEBUG]  loss: 0.23882613921165466\n",
            "2020-08-09 14:38:07,971 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:38:07,971 [MainThread  ][DEBUG]  AUC: 0.8122299313545227\n",
            "2020-08-09 14:38:07,971 [MainThread  ][DEBUG]  val_loss: 0.23911358165740967\n",
            "2020-08-09 14:38:07,972 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:38:07,972 [MainThread  ][DEBUG]  val_AUC: 0.8283379673957825\n",
            "2020-08-09 14:38:22,236 [MainThread  ][DEBUG]  ######## Epoch 45 ########\n",
            "2020-08-09 14:38:22,236 [MainThread  ][DEBUG]  loss: 0.23881294167041778\n",
            "2020-08-09 14:38:22,236 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:38:22,236 [MainThread  ][DEBUG]  AUC: 0.8061279654502869\n",
            "2020-08-09 14:38:22,236 [MainThread  ][DEBUG]  val_loss: 0.23912545800209045\n",
            "2020-08-09 14:38:22,236 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:38:22,236 [MainThread  ][DEBUG]  val_AUC: 0.8270599842071533\n",
            "2020-08-09 14:38:36,525 [MainThread  ][DEBUG]  ######## Epoch 46 ########\n",
            "2020-08-09 14:38:36,525 [MainThread  ][DEBUG]  loss: 0.23884599769115447\n",
            "2020-08-09 14:38:36,525 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:38:36,525 [MainThread  ][DEBUG]  AUC: 0.8116920590400696\n",
            "2020-08-09 14:38:36,525 [MainThread  ][DEBUG]  val_loss: 0.23911462783813475\n",
            "2020-08-09 14:38:36,526 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:38:36,526 [MainThread  ][DEBUG]  val_AUC: 0.8283560276031494\n",
            "2020-08-09 14:38:50,760 [MainThread  ][DEBUG]  ######## Epoch 47 ########\n",
            "2020-08-09 14:38:50,760 [MainThread  ][DEBUG]  loss: 0.2388095188140869\n",
            "2020-08-09 14:38:50,760 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:38:50,760 [MainThread  ][DEBUG]  AUC: 0.8113719820976257\n",
            "2020-08-09 14:38:50,760 [MainThread  ][DEBUG]  val_loss: 0.23913812744617463\n",
            "2020-08-09 14:38:50,760 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:38:50,760 [MainThread  ][DEBUG]  val_AUC: 0.8264240026473999\n",
            "2020-08-09 14:39:05,029 [MainThread  ][DEBUG]  ######## Epoch 48 ########\n",
            "2020-08-09 14:39:05,029 [MainThread  ][DEBUG]  loss: 0.2388058671951294\n",
            "2020-08-09 14:39:05,029 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:39:05,029 [MainThread  ][DEBUG]  AUC: 0.8068140149116516\n",
            "2020-08-09 14:39:05,029 [MainThread  ][DEBUG]  val_loss: 0.2391235877275467\n",
            "2020-08-09 14:39:05,029 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:39:05,029 [MainThread  ][DEBUG]  val_AUC: 0.8250000476837158\n",
            "2020-08-09 14:39:19,331 [MainThread  ][DEBUG]  ######## Epoch 49 ########\n",
            "2020-08-09 14:39:19,331 [MainThread  ][DEBUG]  loss: 0.23880961596965788\n",
            "2020-08-09 14:39:19,331 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:39:19,331 [MainThread  ][DEBUG]  AUC: 0.8106520175933838\n",
            "2020-08-09 14:39:19,331 [MainThread  ][DEBUG]  val_loss: 0.23910915088653564\n",
            "2020-08-09 14:39:19,331 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:39:19,331 [MainThread  ][DEBUG]  val_AUC: 0.8281580209732056\n",
            "2020-08-09 14:39:33,636 [MainThread  ][DEBUG]  ######## Epoch 50 ########\n",
            "2020-08-09 14:39:33,637 [MainThread  ][DEBUG]  loss: 0.23881680583953857\n",
            "2020-08-09 14:39:33,637 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:39:33,637 [MainThread  ][DEBUG]  AUC: 0.8088260889053345\n",
            "2020-08-09 14:39:33,637 [MainThread  ][DEBUG]  val_loss: 0.23915462005138396\n",
            "2020-08-09 14:39:33,637 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6779999732971191\n",
            "2020-08-09 14:39:33,637 [MainThread  ][DEBUG]  val_AUC: 0.8171460628509521\n",
            "2020-08-09 14:39:47,889 [MainThread  ][DEBUG]  ######## Epoch 51 ########\n",
            "2020-08-09 14:39:47,889 [MainThread  ][DEBUG]  loss: 0.23882443511486054\n",
            "2020-08-09 14:39:47,889 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:39:47,889 [MainThread  ][DEBUG]  AUC: 0.8086459040641785\n",
            "2020-08-09 14:39:47,889 [MainThread  ][DEBUG]  val_loss: 0.23912537097930908\n",
            "2020-08-09 14:39:47,889 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:39:47,889 [MainThread  ][DEBUG]  val_AUC: 0.8221240639686584\n",
            "2020-08-09 14:40:02,183 [MainThread  ][DEBUG]  ######## Epoch 52 ########\n",
            "2020-08-09 14:40:02,183 [MainThread  ][DEBUG]  loss: 0.2388096628189087\n",
            "2020-08-09 14:40:02,183 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:40:02,184 [MainThread  ][DEBUG]  AUC: 0.8088060021400452\n",
            "2020-08-09 14:40:02,184 [MainThread  ][DEBUG]  val_loss: 0.23911182296276093\n",
            "2020-08-09 14:40:02,184 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:40:02,184 [MainThread  ][DEBUG]  val_AUC: 0.8295979499816895\n",
            "2020-08-09 14:40:16,492 [MainThread  ][DEBUG]  ######## Epoch 53 ########\n",
            "2020-08-09 14:40:16,492 [MainThread  ][DEBUG]  loss: 0.23880364048480987\n",
            "2020-08-09 14:40:16,492 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:40:16,492 [MainThread  ][DEBUG]  AUC: 0.8117759823799133\n",
            "2020-08-09 14:40:16,492 [MainThread  ][DEBUG]  val_loss: 0.23913248908519744\n",
            "2020-08-09 14:40:16,492 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:40:16,492 [MainThread  ][DEBUG]  val_AUC: 0.822163999080658\n",
            "2020-08-09 14:40:30,919 [MainThread  ][DEBUG]  ######## Epoch 54 ########\n",
            "2020-08-09 14:40:30,919 [MainThread  ][DEBUG]  loss: 0.23880726993083953\n",
            "2020-08-09 14:40:30,919 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:40:30,919 [MainThread  ][DEBUG]  AUC: 0.8075640201568604\n",
            "2020-08-09 14:40:30,920 [MainThread  ][DEBUG]  val_loss: 0.23913421237468718\n",
            "2020-08-09 14:40:30,920 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:40:30,920 [MainThread  ][DEBUG]  val_AUC: 0.8173980116844177\n",
            "2020-08-09 14:40:45,297 [MainThread  ][DEBUG]  ######## Epoch 55 ########\n",
            "2020-08-09 14:40:45,297 [MainThread  ][DEBUG]  loss: 0.23880747056007384\n",
            "2020-08-09 14:40:45,297 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:40:45,297 [MainThread  ][DEBUG]  AUC: 0.8082399964332581\n",
            "2020-08-09 14:40:45,297 [MainThread  ][DEBUG]  val_loss: 0.2391268949508667\n",
            "2020-08-09 14:40:45,297 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:40:45,297 [MainThread  ][DEBUG]  val_AUC: 0.8221180438995361\n",
            "2020-08-09 14:40:59,610 [MainThread  ][DEBUG]  ######## Epoch 56 ########\n",
            "2020-08-09 14:40:59,610 [MainThread  ][DEBUG]  loss: 0.23881172680854798\n",
            "2020-08-09 14:40:59,610 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:40:59,610 [MainThread  ][DEBUG]  AUC: 0.8110319375991821\n",
            "2020-08-09 14:40:59,610 [MainThread  ][DEBUG]  val_loss: 0.239109078168869\n",
            "2020-08-09 14:40:59,610 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:40:59,610 [MainThread  ][DEBUG]  val_AUC: 0.8280719518661499\n",
            "2020-08-09 14:41:13,979 [MainThread  ][DEBUG]  ######## Epoch 57 ########\n",
            "2020-08-09 14:41:13,979 [MainThread  ][DEBUG]  loss: 0.238818457365036\n",
            "2020-08-09 14:41:13,979 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:41:13,979 [MainThread  ][DEBUG]  AUC: 0.8097840547561646\n",
            "2020-08-09 14:41:13,979 [MainThread  ][DEBUG]  val_loss: 0.23914517104625702\n",
            "2020-08-09 14:41:13,979 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6809999942779541\n",
            "2020-08-09 14:41:13,979 [MainThread  ][DEBUG]  val_AUC: 0.8177280426025391\n",
            "2020-08-09 14:41:28,252 [MainThread  ][DEBUG]  ######## Epoch 58 ########\n",
            "2020-08-09 14:41:28,253 [MainThread  ][DEBUG]  loss: 0.23880076038837433\n",
            "2020-08-09 14:41:28,253 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:41:28,253 [MainThread  ][DEBUG]  AUC: 0.8082320094108582\n",
            "2020-08-09 14:41:28,253 [MainThread  ][DEBUG]  val_loss: 0.2391202381849289\n",
            "2020-08-09 14:41:28,253 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:41:28,253 [MainThread  ][DEBUG]  val_AUC: 0.8249940276145935\n",
            "2020-08-09 14:41:42,511 [MainThread  ][DEBUG]  ######## Epoch 59 ########\n",
            "2020-08-09 14:41:42,511 [MainThread  ][DEBUG]  loss: 0.23885483074188232\n",
            "2020-08-09 14:41:42,511 [MainThread  ][DEBUG]  binary_accuracy: 0.6959999799728394\n",
            "2020-08-09 14:41:42,511 [MainThread  ][DEBUG]  AUC: 0.8120540380477905\n",
            "2020-08-09 14:41:42,511 [MainThread  ][DEBUG]  val_loss: 0.23910227406024934\n",
            "2020-08-09 14:41:42,511 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6899999976158142\n",
            "2020-08-09 14:41:42,511 [MainThread  ][DEBUG]  val_AUC: 0.8284199833869934\n",
            "2020-08-09 14:41:56,823 [MainThread  ][DEBUG]  ######## Epoch 60 ########\n",
            "2020-08-09 14:41:56,824 [MainThread  ][DEBUG]  loss: 0.23881296348571776\n",
            "2020-08-09 14:41:56,824 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:41:56,824 [MainThread  ][DEBUG]  AUC: 0.8112499713897705\n",
            "2020-08-09 14:41:56,824 [MainThread  ][DEBUG]  val_loss: 0.23915291619300844\n",
            "2020-08-09 14:41:56,824 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:41:56,824 [MainThread  ][DEBUG]  val_AUC: 0.8185840249061584\n",
            "2020-08-09 14:42:11,129 [MainThread  ][DEBUG]  ######## Epoch 61 ########\n",
            "2020-08-09 14:42:11,129 [MainThread  ][DEBUG]  loss: 0.23881272685527802\n",
            "2020-08-09 14:42:11,129 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:42:11,129 [MainThread  ][DEBUG]  AUC: 0.807543933391571\n",
            "2020-08-09 14:42:11,129 [MainThread  ][DEBUG]  val_loss: 0.23912084007263185\n",
            "2020-08-09 14:42:11,130 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:42:11,130 [MainThread  ][DEBUG]  val_AUC: 0.8253560662269592\n",
            "2020-08-09 14:42:25,409 [MainThread  ][DEBUG]  ######## Epoch 62 ########\n",
            "2020-08-09 14:42:25,410 [MainThread  ][DEBUG]  loss: 0.23882882571220398\n",
            "2020-08-09 14:42:25,410 [MainThread  ][DEBUG]  binary_accuracy: 0.6890000104904175\n",
            "2020-08-09 14:42:25,410 [MainThread  ][DEBUG]  AUC: 0.8052279949188232\n",
            "2020-08-09 14:42:25,410 [MainThread  ][DEBUG]  val_loss: 0.23913968014717102\n",
            "2020-08-09 14:42:25,410 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6800000071525574\n",
            "2020-08-09 14:42:25,410 [MainThread  ][DEBUG]  val_AUC: 0.8175039291381836\n",
            "2020-08-09 14:42:39,667 [MainThread  ][DEBUG]  ######## Epoch 63 ########\n",
            "2020-08-09 14:42:39,667 [MainThread  ][DEBUG]  loss: 0.23886351585388182\n",
            "2020-08-09 14:42:39,667 [MainThread  ][DEBUG]  binary_accuracy: 0.6959999799728394\n",
            "2020-08-09 14:42:39,667 [MainThread  ][DEBUG]  AUC: 0.8102179765701294\n",
            "2020-08-09 14:42:39,667 [MainThread  ][DEBUG]  val_loss: 0.2391092050075531\n",
            "2020-08-09 14:42:39,667 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6899999976158142\n",
            "2020-08-09 14:42:39,667 [MainThread  ][DEBUG]  val_AUC: 0.8292360305786133\n",
            "2020-08-09 14:42:53,918 [MainThread  ][DEBUG]  ######## Epoch 64 ########\n",
            "2020-08-09 14:42:53,919 [MainThread  ][DEBUG]  loss: 0.2388286259174347\n",
            "2020-08-09 14:42:53,919 [MainThread  ][DEBUG]  binary_accuracy: 0.6899999976158142\n",
            "2020-08-09 14:42:53,919 [MainThread  ][DEBUG]  AUC: 0.8051080703735352\n",
            "2020-08-09 14:42:53,919 [MainThread  ][DEBUG]  val_loss: 0.23915612113475798\n",
            "2020-08-09 14:42:53,919 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6800000071525574\n",
            "2020-08-09 14:42:53,919 [MainThread  ][DEBUG]  val_AUC: 0.8177379965782166\n",
            "2020-08-09 14:43:08,273 [MainThread  ][DEBUG]  ######## Epoch 65 ########\n",
            "2020-08-09 14:43:08,274 [MainThread  ][DEBUG]  loss: 0.23880320084095003\n",
            "2020-08-09 14:43:08,274 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:43:08,274 [MainThread  ][DEBUG]  AUC: 0.8080620169639587\n",
            "2020-08-09 14:43:08,274 [MainThread  ][DEBUG]  val_loss: 0.23911250591278077\n",
            "2020-08-09 14:43:08,274 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:43:08,274 [MainThread  ][DEBUG]  val_AUC: 0.8290140628814697\n",
            "2020-08-09 14:43:22,646 [MainThread  ][DEBUG]  ######## Epoch 66 ########\n",
            "2020-08-09 14:43:22,647 [MainThread  ][DEBUG]  loss: 0.2388071746826172\n",
            "2020-08-09 14:43:22,647 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:43:22,647 [MainThread  ][DEBUG]  AUC: 0.8091899752616882\n",
            "2020-08-09 14:43:22,647 [MainThread  ][DEBUG]  val_loss: 0.23912235903739928\n",
            "2020-08-09 14:43:22,647 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:43:22,647 [MainThread  ][DEBUG]  val_AUC: 0.8220440149307251\n",
            "2020-08-09 14:43:36,974 [MainThread  ][DEBUG]  ######## Epoch 67 ########\n",
            "2020-08-09 14:43:36,974 [MainThread  ][DEBUG]  loss: 0.23881085789203643\n",
            "2020-08-09 14:43:36,974 [MainThread  ][DEBUG]  binary_accuracy: 0.6949999928474426\n",
            "2020-08-09 14:43:36,974 [MainThread  ][DEBUG]  AUC: 0.8112199902534485\n",
            "2020-08-09 14:43:36,974 [MainThread  ][DEBUG]  val_loss: 0.2391096419095993\n",
            "2020-08-09 14:43:36,974 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6880000233650208\n",
            "2020-08-09 14:43:36,974 [MainThread  ][DEBUG]  val_AUC: 0.8299978971481323\n",
            "2020-08-09 14:43:51,278 [MainThread  ][DEBUG]  ######## Epoch 68 ########\n",
            "2020-08-09 14:43:51,278 [MainThread  ][DEBUG]  loss: 0.23881358611583708\n",
            "2020-08-09 14:43:51,278 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:43:51,278 [MainThread  ][DEBUG]  AUC: 0.8104480504989624\n",
            "2020-08-09 14:43:51,278 [MainThread  ][DEBUG]  val_loss: 0.2391210253238678\n",
            "2020-08-09 14:43:51,278 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:43:51,278 [MainThread  ][DEBUG]  val_AUC: 0.8261779546737671\n",
            "2020-08-09 14:44:05,568 [MainThread  ][DEBUG]  ######## Epoch 69 ########\n",
            "2020-08-09 14:44:05,569 [MainThread  ][DEBUG]  loss: 0.23882469391822814\n",
            "2020-08-09 14:44:05,569 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:44:05,569 [MainThread  ][DEBUG]  AUC: 0.8110240697860718\n",
            "2020-08-09 14:44:05,569 [MainThread  ][DEBUG]  val_loss: 0.2391201639175415\n",
            "2020-08-09 14:44:05,569 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:44:05,569 [MainThread  ][DEBUG]  val_AUC: 0.8292000889778137\n",
            "2020-08-09 14:44:19,913 [MainThread  ][DEBUG]  ######## Epoch 70 ########\n",
            "2020-08-09 14:44:19,913 [MainThread  ][DEBUG]  loss: 0.23882496631145478\n",
            "2020-08-09 14:44:19,913 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:44:19,913 [MainThread  ][DEBUG]  AUC: 0.8103680610656738\n",
            "2020-08-09 14:44:19,914 [MainThread  ][DEBUG]  val_loss: 0.23914218306541443\n",
            "2020-08-09 14:44:19,914 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:44:19,914 [MainThread  ][DEBUG]  val_AUC: 0.8207119703292847\n",
            "2020-08-09 14:44:34,187 [MainThread  ][DEBUG]  ######## Epoch 71 ########\n",
            "2020-08-09 14:44:34,187 [MainThread  ][DEBUG]  loss: 0.23880903601646422\n",
            "2020-08-09 14:44:34,187 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:44:34,187 [MainThread  ][DEBUG]  AUC: 0.8084200024604797\n",
            "2020-08-09 14:44:34,187 [MainThread  ][DEBUG]  val_loss: 0.23912503170967103\n",
            "2020-08-09 14:44:34,187 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:44:34,187 [MainThread  ][DEBUG]  val_AUC: 0.8237460255622864\n",
            "2020-08-09 14:44:48,470 [MainThread  ][DEBUG]  ######## Epoch 72 ########\n",
            "2020-08-09 14:44:48,470 [MainThread  ][DEBUG]  loss: 0.2388079788684845\n",
            "2020-08-09 14:44:48,470 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:44:48,470 [MainThread  ][DEBUG]  AUC: 0.8091959953308105\n",
            "2020-08-09 14:44:48,470 [MainThread  ][DEBUG]  val_loss: 0.2391103994846344\n",
            "2020-08-09 14:44:48,470 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:44:48,470 [MainThread  ][DEBUG]  val_AUC: 0.8286359310150146\n",
            "2020-08-09 14:45:02,798 [MainThread  ][DEBUG]  ######## Epoch 73 ########\n",
            "2020-08-09 14:45:02,798 [MainThread  ][DEBUG]  loss: 0.2388167963027954\n",
            "2020-08-09 14:45:02,798 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:45:02,798 [MainThread  ][DEBUG]  AUC: 0.8053880333900452\n",
            "2020-08-09 14:45:02,798 [MainThread  ][DEBUG]  val_loss: 0.2391275165081024\n",
            "2020-08-09 14:45:02,798 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:45:02,798 [MainThread  ][DEBUG]  val_AUC: 0.8220540285110474\n",
            "2020-08-09 14:45:17,053 [MainThread  ][DEBUG]  ######## Epoch 74 ########\n",
            "2020-08-09 14:45:17,054 [MainThread  ][DEBUG]  loss: 0.23881770122051238\n",
            "2020-08-09 14:45:17,054 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:45:17,054 [MainThread  ][DEBUG]  AUC: 0.8081480264663696\n",
            "2020-08-09 14:45:17,054 [MainThread  ][DEBUG]  val_loss: 0.23912479031085968\n",
            "2020-08-09 14:45:17,054 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:45:17,054 [MainThread  ][DEBUG]  val_AUC: 0.8220540285110474\n",
            "2020-08-09 14:45:31,353 [MainThread  ][DEBUG]  ######## Epoch 75 ########\n",
            "2020-08-09 14:45:31,353 [MainThread  ][DEBUG]  loss: 0.23881075167655944\n",
            "2020-08-09 14:45:31,353 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:45:31,353 [MainThread  ][DEBUG]  AUC: 0.8103560209274292\n",
            "2020-08-09 14:45:31,353 [MainThread  ][DEBUG]  val_loss: 0.23911661744117738\n",
            "2020-08-09 14:45:31,353 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:45:31,353 [MainThread  ][DEBUG]  val_AUC: 0.8291741013526917\n",
            "2020-08-09 14:45:45,768 [MainThread  ][DEBUG]  ######## Epoch 76 ########\n",
            "2020-08-09 14:45:45,768 [MainThread  ][DEBUG]  loss: 0.23881348991394044\n",
            "2020-08-09 14:45:45,768 [MainThread  ][DEBUG]  binary_accuracy: 0.6949999928474426\n",
            "2020-08-09 14:45:45,768 [MainThread  ][DEBUG]  AUC: 0.8110899925231934\n",
            "2020-08-09 14:45:45,768 [MainThread  ][DEBUG]  val_loss: 0.2391264135837555\n",
            "2020-08-09 14:45:45,769 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:45:45,769 [MainThread  ][DEBUG]  val_AUC: 0.8290860652923584\n",
            "2020-08-09 14:46:00,168 [MainThread  ][DEBUG]  ######## Epoch 77 ########\n",
            "2020-08-09 14:46:00,168 [MainThread  ][DEBUG]  loss: 0.23880939102172852\n",
            "2020-08-09 14:46:00,168 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:46:00,168 [MainThread  ][DEBUG]  AUC: 0.8112860321998596\n",
            "2020-08-09 14:46:00,168 [MainThread  ][DEBUG]  val_loss: 0.2391187365055084\n",
            "2020-08-09 14:46:00,168 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:46:00,169 [MainThread  ][DEBUG]  val_AUC: 0.8281779289245605\n",
            "2020-08-09 14:46:14,860 [MainThread  ][DEBUG]  ######## Epoch 78 ########\n",
            "2020-08-09 14:46:14,860 [MainThread  ][DEBUG]  loss: 0.23880886483192443\n",
            "2020-08-09 14:46:14,860 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:46:14,860 [MainThread  ][DEBUG]  AUC: 0.8091579079627991\n",
            "2020-08-09 14:46:14,860 [MainThread  ][DEBUG]  val_loss: 0.23912451565265655\n",
            "2020-08-09 14:46:14,860 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:46:14,860 [MainThread  ][DEBUG]  val_AUC: 0.8282179832458496\n",
            "2020-08-09 14:46:30,052 [MainThread  ][DEBUG]  ######## Epoch 79 ########\n",
            "2020-08-09 14:46:30,052 [MainThread  ][DEBUG]  loss: 0.23881305813789366\n",
            "2020-08-09 14:46:30,052 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:46:30,052 [MainThread  ][DEBUG]  AUC: 0.8081480860710144\n",
            "2020-08-09 14:46:30,052 [MainThread  ][DEBUG]  val_loss: 0.23913285923004152\n",
            "2020-08-09 14:46:30,052 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:46:30,052 [MainThread  ][DEBUG]  val_AUC: 0.8228620290756226\n",
            "2020-08-09 14:46:44,361 [MainThread  ][DEBUG]  ######## Epoch 80 ########\n",
            "2020-08-09 14:46:44,362 [MainThread  ][DEBUG]  loss: 0.2388096534013748\n",
            "2020-08-09 14:46:44,362 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:46:44,362 [MainThread  ][DEBUG]  AUC: 0.8123059868812561\n",
            "2020-08-09 14:46:44,362 [MainThread  ][DEBUG]  val_loss: 0.23911340928077698\n",
            "2020-08-09 14:46:44,362 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:46:44,362 [MainThread  ][DEBUG]  val_AUC: 0.8286879658699036\n",
            "2020-08-09 14:46:58,639 [MainThread  ][DEBUG]  ######## Epoch 81 ########\n",
            "2020-08-09 14:46:58,640 [MainThread  ][DEBUG]  loss: 0.23880763816833497\n",
            "2020-08-09 14:46:58,640 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:46:58,640 [MainThread  ][DEBUG]  AUC: 0.8115799427032471\n",
            "2020-08-09 14:46:58,640 [MainThread  ][DEBUG]  val_loss: 0.23912431406974793\n",
            "2020-08-09 14:46:58,640 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6850000023841858\n",
            "2020-08-09 14:46:58,640 [MainThread  ][DEBUG]  val_AUC: 0.8272640109062195\n",
            "2020-08-09 14:47:12,917 [MainThread  ][DEBUG]  ######## Epoch 82 ########\n",
            "2020-08-09 14:47:12,917 [MainThread  ][DEBUG]  loss: 0.238806809425354\n",
            "2020-08-09 14:47:12,917 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:47:12,917 [MainThread  ][DEBUG]  AUC: 0.806876003742218\n",
            "2020-08-09 14:47:12,917 [MainThread  ][DEBUG]  val_loss: 0.23912307822704315\n",
            "2020-08-09 14:47:12,917 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:47:12,917 [MainThread  ][DEBUG]  val_AUC: 0.8252040147781372\n",
            "2020-08-09 14:47:27,165 [MainThread  ][DEBUG]  ######## Epoch 83 ########\n",
            "2020-08-09 14:47:27,165 [MainThread  ][DEBUG]  loss: 0.23882174575328827\n",
            "2020-08-09 14:47:27,165 [MainThread  ][DEBUG]  binary_accuracy: 0.6959999799728394\n",
            "2020-08-09 14:47:27,165 [MainThread  ][DEBUG]  AUC: 0.8125579357147217\n",
            "2020-08-09 14:47:27,165 [MainThread  ][DEBUG]  val_loss: 0.23910523867607117\n",
            "2020-08-09 14:47:27,165 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6899999976158142\n",
            "2020-08-09 14:47:27,165 [MainThread  ][DEBUG]  val_AUC: 0.8300360441207886\n",
            "2020-08-09 14:47:41,435 [MainThread  ][DEBUG]  ######## Epoch 84 ########\n",
            "2020-08-09 14:47:41,435 [MainThread  ][DEBUG]  loss: 0.2388201915025711\n",
            "2020-08-09 14:47:41,435 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:47:41,435 [MainThread  ][DEBUG]  AUC: 0.8051060438156128\n",
            "2020-08-09 14:47:41,435 [MainThread  ][DEBUG]  val_loss: 0.23915474212169646\n",
            "2020-08-09 14:47:41,436 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6800000071525574\n",
            "2020-08-09 14:47:41,436 [MainThread  ][DEBUG]  val_AUC: 0.81687992811203\n",
            "2020-08-09 14:47:55,604 [MainThread  ][DEBUG]  ######## Epoch 85 ########\n",
            "2020-08-09 14:47:55,604 [MainThread  ][DEBUG]  loss: 0.2388086680173874\n",
            "2020-08-09 14:47:55,604 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:47:55,604 [MainThread  ][DEBUG]  AUC: 0.8070999383926392\n",
            "2020-08-09 14:47:55,604 [MainThread  ][DEBUG]  val_loss: 0.23911284255981446\n",
            "2020-08-09 14:47:55,604 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:47:55,604 [MainThread  ][DEBUG]  val_AUC: 0.8300020098686218\n",
            "2020-08-09 14:48:10,003 [MainThread  ][DEBUG]  ######## Epoch 86 ########\n",
            "2020-08-09 14:48:10,003 [MainThread  ][DEBUG]  loss: 0.23880976092815398\n",
            "2020-08-09 14:48:10,003 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:48:10,003 [MainThread  ][DEBUG]  AUC: 0.8105120062828064\n",
            "2020-08-09 14:48:10,003 [MainThread  ][DEBUG]  val_loss: 0.2391110837459564\n",
            "2020-08-09 14:48:10,003 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:48:10,004 [MainThread  ][DEBUG]  val_AUC: 0.8280678987503052\n",
            "2020-08-09 14:48:24,238 [MainThread  ][DEBUG]  ######## Epoch 87 ########\n",
            "2020-08-09 14:48:24,238 [MainThread  ][DEBUG]  loss: 0.23880799508094788\n",
            "2020-08-09 14:48:24,238 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:48:24,238 [MainThread  ][DEBUG]  AUC: 0.8101741075515747\n",
            "2020-08-09 14:48:24,238 [MainThread  ][DEBUG]  val_loss: 0.2391264832019806\n",
            "2020-08-09 14:48:24,238 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:48:24,239 [MainThread  ][DEBUG]  val_AUC: 0.8220100402832031\n",
            "2020-08-09 14:48:38,493 [MainThread  ][DEBUG]  ######## Epoch 88 ########\n",
            "2020-08-09 14:48:38,493 [MainThread  ][DEBUG]  loss: 0.23880775260925294\n",
            "2020-08-09 14:48:38,493 [MainThread  ][DEBUG]  binary_accuracy: 0.6930000185966492\n",
            "2020-08-09 14:48:38,493 [MainThread  ][DEBUG]  AUC: 0.8104119896888733\n",
            "2020-08-09 14:48:38,493 [MainThread  ][DEBUG]  val_loss: 0.23911040282249452\n",
            "2020-08-09 14:48:38,493 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:48:38,493 [MainThread  ][DEBUG]  val_AUC: 0.8279039859771729\n",
            "2020-08-09 14:48:52,758 [MainThread  ][DEBUG]  ######## Epoch 89 ########\n",
            "2020-08-09 14:48:52,758 [MainThread  ][DEBUG]  loss: 0.23880481910705567\n",
            "2020-08-09 14:48:52,759 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:48:52,759 [MainThread  ][DEBUG]  AUC: 0.8096858859062195\n",
            "2020-08-09 14:48:52,759 [MainThread  ][DEBUG]  val_loss: 0.23912884044647217\n",
            "2020-08-09 14:48:52,759 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6830000281333923\n",
            "2020-08-09 14:48:52,759 [MainThread  ][DEBUG]  val_AUC: 0.8242939710617065\n",
            "2020-08-09 14:49:07,046 [MainThread  ][DEBUG]  ######## Epoch 90 ########\n",
            "2020-08-09 14:49:07,046 [MainThread  ][DEBUG]  loss: 0.23881132006645203\n",
            "2020-08-09 14:49:07,046 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:49:07,046 [MainThread  ][DEBUG]  AUC: 0.806615948677063\n",
            "2020-08-09 14:49:07,046 [MainThread  ][DEBUG]  val_loss: 0.23913745880126952\n",
            "2020-08-09 14:49:07,046 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:49:07,047 [MainThread  ][DEBUG]  val_AUC: 0.8175840377807617\n",
            "2020-08-09 14:49:21,321 [MainThread  ][DEBUG]  ######## Epoch 91 ########\n",
            "2020-08-09 14:49:21,322 [MainThread  ][DEBUG]  loss: 0.23880200850963593\n",
            "2020-08-09 14:49:21,322 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:49:21,322 [MainThread  ][DEBUG]  AUC: 0.8081219792366028\n",
            "2020-08-09 14:49:21,322 [MainThread  ][DEBUG]  val_loss: 0.23911365532875062\n",
            "2020-08-09 14:49:21,322 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:49:21,322 [MainThread  ][DEBUG]  val_AUC: 0.8294480443000793\n",
            "2020-08-09 14:49:35,588 [MainThread  ][DEBUG]  ######## Epoch 92 ########\n",
            "2020-08-09 14:49:35,588 [MainThread  ][DEBUG]  loss: 0.2388122720718384\n",
            "2020-08-09 14:49:35,588 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:49:35,588 [MainThread  ][DEBUG]  AUC: 0.8069440126419067\n",
            "2020-08-09 14:49:35,588 [MainThread  ][DEBUG]  val_loss: 0.23912338924407958\n",
            "2020-08-09 14:49:35,588 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:49:35,588 [MainThread  ][DEBUG]  val_AUC: 0.8243499398231506\n",
            "2020-08-09 14:49:49,812 [MainThread  ][DEBUG]  ######## Epoch 93 ########\n",
            "2020-08-09 14:49:49,813 [MainThread  ][DEBUG]  loss: 0.23880897128582002\n",
            "2020-08-09 14:49:49,813 [MainThread  ][DEBUG]  binary_accuracy: 0.6949999928474426\n",
            "2020-08-09 14:49:49,813 [MainThread  ][DEBUG]  AUC: 0.8145319819450378\n",
            "2020-08-09 14:49:49,813 [MainThread  ][DEBUG]  val_loss: 0.23911213314533233\n",
            "2020-08-09 14:49:49,813 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:49:49,813 [MainThread  ][DEBUG]  val_AUC: 0.827597975730896\n",
            "2020-08-09 14:50:04,061 [MainThread  ][DEBUG]  ######## Epoch 94 ########\n",
            "2020-08-09 14:50:04,061 [MainThread  ][DEBUG]  loss: 0.23880674242973327\n",
            "2020-08-09 14:50:04,062 [MainThread  ][DEBUG]  binary_accuracy: 0.6949999928474426\n",
            "2020-08-09 14:50:04,062 [MainThread  ][DEBUG]  AUC: 0.8130199909210205\n",
            "2020-08-09 14:50:04,062 [MainThread  ][DEBUG]  val_loss: 0.23911276054382324\n",
            "2020-08-09 14:50:04,062 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6899999976158142\n",
            "2020-08-09 14:50:04,062 [MainThread  ][DEBUG]  val_AUC: 0.8297580480575562\n",
            "2020-08-09 14:50:18,331 [MainThread  ][DEBUG]  ######## Epoch 95 ########\n",
            "2020-08-09 14:50:18,331 [MainThread  ][DEBUG]  loss: 0.23881984317302704\n",
            "2020-08-09 14:50:18,332 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:50:18,332 [MainThread  ][DEBUG]  AUC: 0.8125720024108887\n",
            "2020-08-09 14:50:18,332 [MainThread  ][DEBUG]  val_loss: 0.23913377845287323\n",
            "2020-08-09 14:50:18,332 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6840000152587891\n",
            "2020-08-09 14:50:18,332 [MainThread  ][DEBUG]  val_AUC: 0.8265159726142883\n",
            "2020-08-09 14:50:32,623 [MainThread  ][DEBUG]  ######## Epoch 96 ########\n",
            "2020-08-09 14:50:32,623 [MainThread  ][DEBUG]  loss: 0.23881175518035888\n",
            "2020-08-09 14:50:32,623 [MainThread  ][DEBUG]  binary_accuracy: 0.6909999847412109\n",
            "2020-08-09 14:50:32,623 [MainThread  ][DEBUG]  AUC: 0.8096320033073425\n",
            "2020-08-09 14:50:32,623 [MainThread  ][DEBUG]  val_loss: 0.23911652636528016\n",
            "2020-08-09 14:50:32,623 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:50:32,623 [MainThread  ][DEBUG]  val_AUC: 0.8291460871696472\n",
            "2020-08-09 14:50:46,850 [MainThread  ][DEBUG]  ######## Epoch 97 ########\n",
            "2020-08-09 14:50:46,850 [MainThread  ][DEBUG]  loss: 0.2388382294178009\n",
            "2020-08-09 14:50:46,850 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:50:46,850 [MainThread  ][DEBUG]  AUC: 0.8064720630645752\n",
            "2020-08-09 14:50:46,850 [MainThread  ][DEBUG]  val_loss: 0.23910903954505922\n",
            "2020-08-09 14:50:46,850 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6869999766349792\n",
            "2020-08-09 14:50:46,851 [MainThread  ][DEBUG]  val_AUC: 0.828671932220459\n",
            "2020-08-09 14:51:01,243 [MainThread  ][DEBUG]  ######## Epoch 98 ########\n",
            "2020-08-09 14:51:01,243 [MainThread  ][DEBUG]  loss: 0.23881870436668395\n",
            "2020-08-09 14:51:01,243 [MainThread  ][DEBUG]  binary_accuracy: 0.6940000057220459\n",
            "2020-08-09 14:51:01,243 [MainThread  ][DEBUG]  AUC: 0.8104240298271179\n",
            "2020-08-09 14:51:01,243 [MainThread  ][DEBUG]  val_loss: 0.23911751437187195\n",
            "2020-08-09 14:51:01,244 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6859999895095825\n",
            "2020-08-09 14:51:01,244 [MainThread  ][DEBUG]  val_AUC: 0.8291680812835693\n",
            "2020-08-09 14:51:15,652 [MainThread  ][DEBUG]  ######## Epoch 99 ########\n",
            "2020-08-09 14:51:15,652 [MainThread  ][DEBUG]  loss: 0.23882522654533386\n",
            "2020-08-09 14:51:15,652 [MainThread  ][DEBUG]  binary_accuracy: 0.6919999718666077\n",
            "2020-08-09 14:51:15,652 [MainThread  ][DEBUG]  AUC: 0.8074379563331604\n",
            "2020-08-09 14:51:15,652 [MainThread  ][DEBUG]  val_loss: 0.23914125657081603\n",
            "2020-08-09 14:51:15,652 [MainThread  ][DEBUG]  val_binary_accuracy: 0.6819999814033508\n",
            "2020-08-09 14:51:15,652 [MainThread  ][DEBUG]  val_AUC: 0.8184000253677368\n",
            "2020-08-09 14:51:15,654 [MainThread  ][INFO ]  ######## Training Ends ########\n",
            "2020-08-09 14:51:15,663 [MainThread  ][INFO ]  Model weights: \n",
            "[ 8.8740838e-01  5.6962819e+00 -5.5508539e-02  4.7184024e+00\n",
            "  4.8664904e+00  3.1296399e-01  4.6454296e+00  3.6543555e+00\n",
            "  1.6109911e+00  4.7911825e+00  3.5413194e-01  2.6348860e+00\n",
            "  5.9223952e+00  2.6487622e+00  4.7125115e+00  1.2048173e+00\n",
            "  2.5141828e+00  2.8927550e+00  4.4965205e+00  5.4954624e+00\n",
            "  9.9750727e-01  5.9994340e+00 -3.4908304e-04  5.1231112e+00\n",
            "  2.6524866e+00  4.7019234e+00  1.7384317e+00  8.2696658e-01\n",
            "  3.9223645e+00  4.4099178e+00]\n",
            "2020-08-09 14:51:18,260 [MainThread  ][INFO ]  ######## Test Begins ########\n",
            "2020-08-09 14:51:18,261 [MainThread  ][INFO ]  Number of samples for Testing: 1000\n",
            "2020-08-09 14:51:18,264 [MainThread  ][INFO ]  Number of Epochs: 1\n",
            "2020-08-09 14:51:18,266 [MainThread  ][INFO ]  Batch Size: 32\n",
            "2020-08-09 14:51:19,479 [MainThread  ][INFO ]  *Note: for tensorflow version < 2.3.0, the test results are not loaded into logs\n",
            "2020-08-09 14:51:19,483 [MainThread  ][INFO ]  ######## Test Ends ########\n",
            "2020-08-09 14:51:20,700 [MainThread  ][DEBUG]  ######## ROC curve information ########\n",
            "2020-08-09 14:51:20,703 [MainThread  ][DEBUG]  fpr:\n",
            "[0.    0.    0.    0.002 0.002 0.004 0.004 0.006 0.006 0.008 0.008 0.01\n",
            " 0.01  0.012 0.012 0.014 0.014 0.016 0.016 0.018 0.018 0.02  0.02  0.022\n",
            " 0.022 0.024 0.024 0.026 0.026 0.028 0.028 0.03  0.03  0.032 0.032 0.034\n",
            " 0.034 0.036 0.036 0.038 0.038 0.04  0.04  0.044 0.044 0.046 0.046 0.048\n",
            " 0.048 0.052 0.052 0.054 0.054 0.056 0.056 0.058 0.058 0.06  0.06  0.064\n",
            " 0.064 0.066 0.066 0.068 0.068 0.072 0.072 0.072 0.072 0.074 0.074 0.076\n",
            " 0.076 0.078 0.078 0.08  0.08  0.082 0.082 0.086 0.086 0.088 0.088 0.09\n",
            " 0.09  0.092 0.092 0.094 0.094 0.098 0.098 0.1   0.1   0.102 0.102 0.106\n",
            " 0.106 0.11  0.11  0.112 0.112 0.116 0.116 0.118 0.118 0.12  0.12  0.122\n",
            " 0.122 0.124 0.124 0.126 0.126 0.128 0.128 0.13  0.13  0.132 0.132 0.134\n",
            " 0.134 0.138 0.138 0.14  0.14  0.144 0.144 0.148 0.148 0.15  0.15  0.152\n",
            " 0.152 0.156 0.156 0.158 0.158 0.162 0.162 0.168 0.168 0.172 0.172 0.178\n",
            " 0.178 0.184 0.184 0.188 0.188 0.192 0.192 0.194 0.194 0.204 0.204 0.206\n",
            " 0.206 0.208 0.208 0.21  0.21  0.218 0.218 0.22  0.22  0.226 0.226 0.228\n",
            " 0.228 0.23  0.23  0.236 0.236 0.242 0.242 0.244 0.244 0.246 0.246 0.248\n",
            " 0.248 0.258 0.258 0.262 0.262 0.264 0.264 0.266 0.266 0.274 0.274 0.278\n",
            " 0.278 0.284 0.284 0.292 0.292 0.296 0.296 0.302 0.302 0.304 0.304 0.322\n",
            " 0.322 0.326 0.326 0.332 0.332 0.342 0.342 0.346 0.346 0.348 0.348 0.352\n",
            " 0.352 0.354 0.354 0.356 0.356 0.36  0.36  0.368 0.368 0.37  0.37  0.372\n",
            " 0.372 0.376 0.376 0.386 0.386 0.388 0.388 0.392 0.392 0.394 0.394 0.402\n",
            " 0.402 0.404 0.404 0.408 0.408 0.424 0.424 0.426 0.426 0.442 0.442 0.468\n",
            " 0.468 0.48  0.48  0.486 0.486 0.494 0.494 0.502 0.502 0.514 0.514 0.528\n",
            " 0.528 0.53  0.53  0.534 0.534 0.54  0.54  0.544 0.544 0.57  0.57  0.578\n",
            " 0.578 0.582 0.582 0.586 0.586 0.598 0.598 0.612 0.612 0.626 0.626 0.628\n",
            " 0.628 0.632 0.632 0.64  0.64  0.642 0.642 0.666 0.666 0.672 0.672 0.698\n",
            " 0.698 0.704 0.704 0.706 0.706 0.728 0.728 0.746 0.746 0.754 0.758 0.772\n",
            " 0.772 0.788 0.788 0.792 0.792 0.816 0.816 0.818 0.818 0.828 0.828 0.85\n",
            " 0.85  0.86  0.86  0.862 0.866 0.874 0.874 0.894 0.894 0.94  0.94  0.946\n",
            " 0.946 0.98  0.98  0.99  0.99  0.998 0.998 1.   ]\n",
            "2020-08-09 14:51:20,706 [MainThread  ][DEBUG]  tpr:\n",
            "[0.    0.002 0.006 0.006 0.01  0.01  0.058 0.058 0.09  0.09  0.094 0.094\n",
            " 0.102 0.102 0.166 0.166 0.168 0.168 0.184 0.184 0.204 0.204 0.224 0.224\n",
            " 0.226 0.226 0.256 0.256 0.258 0.258 0.302 0.302 0.312 0.312 0.314 0.314\n",
            " 0.316 0.316 0.32  0.32  0.324 0.324 0.342 0.342 0.348 0.348 0.386 0.386\n",
            " 0.392 0.392 0.414 0.414 0.428 0.428 0.438 0.438 0.44  0.44  0.456 0.456\n",
            " 0.462 0.462 0.464 0.464 0.47  0.47  0.48  0.484 0.494 0.494 0.51  0.51\n",
            " 0.516 0.516 0.518 0.518 0.532 0.532 0.536 0.536 0.538 0.538 0.542 0.542\n",
            " 0.544 0.544 0.548 0.548 0.552 0.552 0.554 0.554 0.568 0.568 0.572 0.572\n",
            " 0.576 0.576 0.58  0.58  0.586 0.586 0.598 0.598 0.602 0.602 0.606 0.606\n",
            " 0.616 0.616 0.618 0.618 0.62  0.62  0.622 0.622 0.624 0.624 0.626 0.626\n",
            " 0.63  0.63  0.632 0.632 0.644 0.644 0.652 0.652 0.658 0.658 0.662 0.662\n",
            " 0.664 0.664 0.668 0.668 0.676 0.676 0.68  0.68  0.682 0.682 0.684 0.684\n",
            " 0.69  0.69  0.692 0.692 0.696 0.696 0.7   0.7   0.702 0.702 0.706 0.706\n",
            " 0.708 0.708 0.71  0.71  0.712 0.712 0.72  0.72  0.722 0.722 0.724 0.724\n",
            " 0.73  0.73  0.732 0.732 0.734 0.734 0.736 0.736 0.738 0.738 0.74  0.74\n",
            " 0.754 0.754 0.764 0.764 0.766 0.766 0.77  0.77  0.78  0.78  0.786 0.786\n",
            " 0.79  0.79  0.792 0.792 0.794 0.794 0.796 0.796 0.798 0.798 0.8   0.8\n",
            " 0.802 0.802 0.806 0.806 0.81  0.81  0.812 0.812 0.814 0.814 0.818 0.818\n",
            " 0.822 0.822 0.824 0.824 0.826 0.826 0.836 0.836 0.838 0.838 0.842 0.842\n",
            " 0.844 0.844 0.846 0.846 0.848 0.848 0.85  0.85  0.852 0.852 0.856 0.856\n",
            " 0.862 0.862 0.864 0.864 0.87  0.87  0.872 0.872 0.874 0.874 0.876 0.876\n",
            " 0.878 0.878 0.88  0.88  0.886 0.886 0.888 0.888 0.892 0.892 0.898 0.898\n",
            " 0.902 0.902 0.906 0.906 0.908 0.908 0.912 0.912 0.914 0.914 0.916 0.916\n",
            " 0.918 0.918 0.92  0.92  0.922 0.922 0.924 0.924 0.926 0.926 0.928 0.928\n",
            " 0.932 0.932 0.936 0.936 0.938 0.938 0.94  0.94  0.942 0.942 0.946 0.946\n",
            " 0.95  0.95  0.952 0.952 0.954 0.954 0.956 0.956 0.958 0.958 0.958 0.958\n",
            " 0.96  0.96  0.962 0.962 0.964 0.964 0.966 0.966 0.972 0.972 0.978 0.978\n",
            " 0.98  0.98  0.982 0.982 0.982 0.982 0.984 0.984 0.988 0.988 0.99  0.99\n",
            " 0.994 0.994 0.996 0.996 0.998 0.998 1.    1.   ]\n",
            "2020-08-09 14:51:20,707 [MainThread  ][DEBUG]  auc:\n",
            "0.823332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kEYbfuXnySH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a67bcde-3323-4193-d887-c0f81d0dff5c"
      },
      "source": [
        "#print out content of the npz logs\n",
        "npzfile = glob.glob('logs/*.npz')[0]\n",
        "print(dict(np.load(npzfile, allow_pickle=True)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train_result': array([{'loss': 0.24769382119178773, 'binary_accuracy': 0.682, 'AUC': 0.71329594, 'val_loss': 0.2456883661746979, 'val_binary_accuracy': 0.636, 'val_AUC': 0.780268, 'epoch': 0},\n",
            "       {'loss': 0.2438567179441452, 'binary_accuracy': 0.646, 'AUC': 0.78235, 'val_loss': 0.24293179893493652, 'val_binary_accuracy': 0.621, 'val_AUC': 0.790874, 'epoch': 1},\n",
            "       {'loss': 0.24175145149230956, 'binary_accuracy': 0.636, 'AUC': 0.800836, 'val_loss': 0.24124643898010253, 'val_binary_accuracy': 0.635, 'val_AUC': 0.82423997, 'epoch': 2},\n",
            "       {'loss': 0.24039606094360352, 'binary_accuracy': 0.669, 'AUC': 0.82566, 'val_loss': 0.24023877227306367, 'val_binary_accuracy': 0.657, 'val_AUC': 0.833496, 'epoch': 3},\n",
            "       {'loss': 0.23951288592815398, 'binary_accuracy': 0.672, 'AUC': 0.8312, 'val_loss': 0.239640572309494, 'val_binary_accuracy': 0.659, 'val_AUC': 0.83329403, 'epoch': 4},\n",
            "       {'loss': 0.23907811570167542, 'binary_accuracy': 0.678, 'AUC': 0.82400405, 'val_loss': 0.23923465085029602, 'val_binary_accuracy': 0.67, 'val_AUC': 0.835698, 'epoch': 5},\n",
            "       {'loss': 0.2388639793395996, 'binary_accuracy': 0.69, 'AUC': 0.822088, 'val_loss': 0.23914411449432374, 'val_binary_accuracy': 0.678, 'val_AUC': 0.82851005, 'epoch': 6},\n",
            "       {'loss': 0.23881413543224334, 'binary_accuracy': 0.69, 'AUC': 0.811908, 'val_loss': 0.23917135071754456, 'val_binary_accuracy': 0.673, 'val_AUC': 0.824436, 'epoch': 7},\n",
            "       {'loss': 0.2388055078983307, 'binary_accuracy': 0.691, 'AUC': 0.80370593, 'val_loss': 0.23912809264659882, 'val_binary_accuracy': 0.682, 'val_AUC': 0.81897, 'epoch': 8},\n",
            "       {'loss': 0.2388449364900589, 'binary_accuracy': 0.689, 'AUC': 0.8057519, 'val_loss': 0.23911425137519837, 'val_binary_accuracy': 0.685, 'val_AUC': 0.82843, 'epoch': 9},\n",
            "       {'loss': 0.23882871556282043, 'binary_accuracy': 0.697, 'AUC': 0.81242, 'val_loss': 0.23910544753074647, 'val_binary_accuracy': 0.689, 'val_AUC': 0.82912403, 'epoch': 10},\n",
            "       {'loss': 0.23880467236042022, 'binary_accuracy': 0.693, 'AUC': 0.813174, 'val_loss': 0.2391307772397995, 'val_binary_accuracy': 0.686, 'val_AUC': 0.8299059, 'epoch': 11},\n",
            "       {'loss': 0.2388093340396881, 'binary_accuracy': 0.691, 'AUC': 0.8097361, 'val_loss': 0.2391212933063507, 'val_binary_accuracy': 0.684, 'val_AUC': 0.82512, 'epoch': 12},\n",
            "       {'loss': 0.23882628428936004, 'binary_accuracy': 0.696, 'AUC': 0.8119901, 'val_loss': 0.2391159029006958, 'val_binary_accuracy': 0.686, 'val_AUC': 0.82890993, 'epoch': 13},\n",
            "       {'loss': 0.23883983063697814, 'binary_accuracy': 0.691, 'AUC': 0.80728006, 'val_loss': 0.23914854717254638, 'val_binary_accuracy': 0.68, 'val_AUC': 0.81773204, 'epoch': 14},\n",
            "       {'loss': 0.23881123530864715, 'binary_accuracy': 0.693, 'AUC': 0.80814403, 'val_loss': 0.23911837017536164, 'val_binary_accuracy': 0.684, 'val_AUC': 0.82537, 'epoch': 15},\n",
            "       {'loss': 0.23880673575401307, 'binary_accuracy': 0.692, 'AUC': 0.80977, 'val_loss': 0.23912431800365447, 'val_binary_accuracy': 0.683, 'val_AUC': 0.82459, 'epoch': 16},\n",
            "       {'loss': 0.23880900490283966, 'binary_accuracy': 0.693, 'AUC': 0.808654, 'val_loss': 0.239114768743515, 'val_binary_accuracy': 0.686, 'val_AUC': 0.83001196, 'epoch': 17},\n",
            "       {'loss': 0.23882689201831817, 'binary_accuracy': 0.689, 'AUC': 0.807548, 'val_loss': 0.23914543163776397, 'val_binary_accuracy': 0.679, 'val_AUC': 0.817288, 'epoch': 18},\n",
            "       {'loss': 0.23880909609794618, 'binary_accuracy': 0.691, 'AUC': 0.80584395, 'val_loss': 0.2391157282590866, 'val_binary_accuracy': 0.685, 'val_AUC': 0.8283739, 'epoch': 19},\n",
            "       {'loss': 0.23880413353443145, 'binary_accuracy': 0.693, 'AUC': 0.8120061, 'val_loss': 0.23911261069774628, 'val_binary_accuracy': 0.686, 'val_AUC': 0.828412, 'epoch': 20},\n",
            "       {'loss': 0.23880574905872345, 'binary_accuracy': 0.692, 'AUC': 0.811322, 'val_loss': 0.23913770389556885, 'val_binary_accuracy': 0.682, 'val_AUC': 0.82064795, 'epoch': 21},\n",
            "       {'loss': 0.23880424296855926, 'binary_accuracy': 0.692, 'AUC': 0.80842197, 'val_loss': 0.2391094034910202, 'val_binary_accuracy': 0.687, 'val_AUC': 0.82799804, 'epoch': 22},\n",
            "       {'loss': 0.2388210029602051, 'binary_accuracy': 0.696, 'AUC': 0.8127141, 'val_loss': 0.23911125266551972, 'val_binary_accuracy': 0.688, 'val_AUC': 0.830184, 'epoch': 23},\n",
            "       {'loss': 0.23880316853523254, 'binary_accuracy': 0.693, 'AUC': 0.809532, 'val_loss': 0.23914091885089875, 'val_binary_accuracy': 0.682, 'val_AUC': 0.82066405, 'epoch': 24},\n",
            "       {'loss': 0.23881815218925476, 'binary_accuracy': 0.692, 'AUC': 0.804376, 'val_loss': 0.2391329925060272, 'val_binary_accuracy': 0.68, 'val_AUC': 0.818064, 'epoch': 25},\n",
            "       {'loss': 0.23883540737628936, 'binary_accuracy': 0.695, 'AUC': 0.81068397, 'val_loss': 0.23911796295642854, 'val_binary_accuracy': 0.686, 'val_AUC': 0.830018, 'epoch': 26},\n",
            "       {'loss': 0.23881191730499268, 'binary_accuracy': 0.692, 'AUC': 0.80780405, 'val_loss': 0.23915413069725036, 'val_binary_accuracy': 0.678, 'val_AUC': 0.81531405, 'epoch': 27},\n",
            "       {'loss': 0.23881535065174103, 'binary_accuracy': 0.692, 'AUC': 0.8079021, 'val_loss': 0.239113933801651, 'val_binary_accuracy': 0.686, 'val_AUC': 0.83002394, 'epoch': 28},\n",
            "       {'loss': 0.238809876203537, 'binary_accuracy': 0.694, 'AUC': 0.80756, 'val_loss': 0.23915442955493926, 'val_binary_accuracy': 0.678, 'val_AUC': 0.81647, 'epoch': 29},\n",
            "       {'loss': 0.23882390856742858, 'binary_accuracy': 0.693, 'AUC': 0.80929, 'val_loss': 0.23912940096855165, 'val_binary_accuracy': 0.684, 'val_AUC': 0.82514197, 'epoch': 30},\n",
            "       {'loss': 0.2388132563829422, 'binary_accuracy': 0.691, 'AUC': 0.8058421, 'val_loss': 0.23911721587181092, 'val_binary_accuracy': 0.685, 'val_AUC': 0.82580197, 'epoch': 31},\n",
            "       {'loss': 0.23880396723747255, 'binary_accuracy': 0.692, 'AUC': 0.809156, 'val_loss': 0.23912533962726593, 'val_binary_accuracy': 0.683, 'val_AUC': 0.82386005, 'epoch': 32},\n",
            "       {'loss': 0.23880968070030212, 'binary_accuracy': 0.691, 'AUC': 0.80726403, 'val_loss': 0.23911446368694306, 'val_binary_accuracy': 0.686, 'val_AUC': 0.83001196, 'epoch': 33},\n",
            "       {'loss': 0.23881271636486054, 'binary_accuracy': 0.69, 'AUC': 0.80756396, 'val_loss': 0.23913339412212373, 'val_binary_accuracy': 0.682, 'val_AUC': 0.817398, 'epoch': 34},\n",
            "       {'loss': 0.2388382260799408, 'binary_accuracy': 0.694, 'AUC': 0.80960596, 'val_loss': 0.23911877655982972, 'val_binary_accuracy': 0.685, 'val_AUC': 0.82900995, 'epoch': 35},\n",
            "       {'loss': 0.23882824420928955, 'binary_accuracy': 0.696, 'AUC': 0.810138, 'val_loss': 0.2391228702068329, 'val_binary_accuracy': 0.686, 'val_AUC': 0.828568, 'epoch': 36},\n",
            "       {'loss': 0.2388041160106659, 'binary_accuracy': 0.691, 'AUC': 0.80604196, 'val_loss': 0.23914275550842284, 'val_binary_accuracy': 0.682, 'val_AUC': 0.81784004, 'epoch': 37},\n",
            "       {'loss': 0.238806786775589, 'binary_accuracy': 0.691, 'AUC': 0.809618, 'val_loss': 0.23911840891838074, 'val_binary_accuracy': 0.685, 'val_AUC': 0.826158, 'epoch': 38},\n",
            "       {'loss': 0.2388119419813156, 'binary_accuracy': 0.691, 'AUC': 0.80763406, 'val_loss': 0.23914036297798158, 'val_binary_accuracy': 0.681, 'val_AUC': 0.817786, 'epoch': 39},\n",
            "       {'loss': 0.23881364810466765, 'binary_accuracy': 0.691, 'AUC': 0.80754596, 'val_loss': 0.23911959052085877, 'val_binary_accuracy': 0.684, 'val_AUC': 0.825352, 'epoch': 40},\n",
            "       {'loss': 0.23881575286388398, 'binary_accuracy': 0.691, 'AUC': 0.806482, 'val_loss': 0.23913013064861297, 'val_binary_accuracy': 0.682, 'val_AUC': 0.822262, 'epoch': 41},\n",
            "       {'loss': 0.23880565178394317, 'binary_accuracy': 0.691, 'AUC': 0.80926204, 'val_loss': 0.2391237906217575, 'val_binary_accuracy': 0.684, 'val_AUC': 0.825114, 'epoch': 42},\n",
            "       {'loss': 0.23881817042827605, 'binary_accuracy': 0.689, 'AUC': 0.80471593, 'val_loss': 0.2391280119419098, 'val_binary_accuracy': 0.682, 'val_AUC': 0.81812, 'epoch': 43},\n",
            "       {'loss': 0.23882613921165466, 'binary_accuracy': 0.692, 'AUC': 0.81222993, 'val_loss': 0.23911358165740967, 'val_binary_accuracy': 0.686, 'val_AUC': 0.82833797, 'epoch': 44},\n",
            "       {'loss': 0.23881294167041778, 'binary_accuracy': 0.692, 'AUC': 0.80612797, 'val_loss': 0.23912545800209045, 'val_binary_accuracy': 0.685, 'val_AUC': 0.82706, 'epoch': 45},\n",
            "       {'loss': 0.23884599769115447, 'binary_accuracy': 0.694, 'AUC': 0.81169206, 'val_loss': 0.23911462783813475, 'val_binary_accuracy': 0.687, 'val_AUC': 0.828356, 'epoch': 46},\n",
            "       {'loss': 0.2388095188140869, 'binary_accuracy': 0.694, 'AUC': 0.811372, 'val_loss': 0.23913812744617463, 'val_binary_accuracy': 0.684, 'val_AUC': 0.826424, 'epoch': 47},\n",
            "       {'loss': 0.2388058671951294, 'binary_accuracy': 0.691, 'AUC': 0.806814, 'val_loss': 0.2391235877275467, 'val_binary_accuracy': 0.684, 'val_AUC': 0.82500005, 'epoch': 48},\n",
            "       {'loss': 0.23880961596965788, 'binary_accuracy': 0.693, 'AUC': 0.810652, 'val_loss': 0.23910915088653564, 'val_binary_accuracy': 0.687, 'val_AUC': 0.828158, 'epoch': 49},\n",
            "       {'loss': 0.23881680583953857, 'binary_accuracy': 0.691, 'AUC': 0.8088261, 'val_loss': 0.23915462005138396, 'val_binary_accuracy': 0.678, 'val_AUC': 0.81714606, 'epoch': 50},\n",
            "       {'loss': 0.23882443511486054, 'binary_accuracy': 0.692, 'AUC': 0.8086459, 'val_loss': 0.23912537097930908, 'val_binary_accuracy': 0.682, 'val_AUC': 0.82212406, 'epoch': 51},\n",
            "       {'loss': 0.2388096628189087, 'binary_accuracy': 0.692, 'AUC': 0.808806, 'val_loss': 0.23911182296276093, 'val_binary_accuracy': 0.686, 'val_AUC': 0.82959795, 'epoch': 52},\n",
            "       {'loss': 0.23880364048480987, 'binary_accuracy': 0.691, 'AUC': 0.811776, 'val_loss': 0.23913248908519744, 'val_binary_accuracy': 0.682, 'val_AUC': 0.822164, 'epoch': 53},\n",
            "       {'loss': 0.23880726993083953, 'binary_accuracy': 0.691, 'AUC': 0.807564, 'val_loss': 0.23913421237468718, 'val_binary_accuracy': 0.682, 'val_AUC': 0.817398, 'epoch': 54},\n",
            "       {'loss': 0.23880747056007384, 'binary_accuracy': 0.691, 'AUC': 0.80824, 'val_loss': 0.2391268949508667, 'val_binary_accuracy': 0.682, 'val_AUC': 0.82211804, 'epoch': 55},\n",
            "       {'loss': 0.23881172680854798, 'binary_accuracy': 0.693, 'AUC': 0.81103194, 'val_loss': 0.239109078168869, 'val_binary_accuracy': 0.687, 'val_AUC': 0.82807195, 'epoch': 56},\n",
            "       {'loss': 0.238818457365036, 'binary_accuracy': 0.692, 'AUC': 0.80978405, 'val_loss': 0.23914517104625702, 'val_binary_accuracy': 0.681, 'val_AUC': 0.81772804, 'epoch': 57},\n",
            "       {'loss': 0.23880076038837433, 'binary_accuracy': 0.691, 'AUC': 0.808232, 'val_loss': 0.2391202381849289, 'val_binary_accuracy': 0.684, 'val_AUC': 0.824994, 'epoch': 58},\n",
            "       {'loss': 0.23885483074188232, 'binary_accuracy': 0.696, 'AUC': 0.81205404, 'val_loss': 0.23910227406024934, 'val_binary_accuracy': 0.69, 'val_AUC': 0.82842, 'epoch': 59},\n",
            "       {'loss': 0.23881296348571776, 'binary_accuracy': 0.692, 'AUC': 0.81125, 'val_loss': 0.23915291619300844, 'val_binary_accuracy': 0.682, 'val_AUC': 0.818584, 'epoch': 60},\n",
            "       {'loss': 0.23881272685527802, 'binary_accuracy': 0.691, 'AUC': 0.80754393, 'val_loss': 0.23912084007263185, 'val_binary_accuracy': 0.684, 'val_AUC': 0.82535607, 'epoch': 61},\n",
            "       {'loss': 0.23882882571220398, 'binary_accuracy': 0.689, 'AUC': 0.805228, 'val_loss': 0.23913968014717102, 'val_binary_accuracy': 0.68, 'val_AUC': 0.8175039, 'epoch': 62},\n",
            "       {'loss': 0.23886351585388182, 'binary_accuracy': 0.696, 'AUC': 0.810218, 'val_loss': 0.2391092050075531, 'val_binary_accuracy': 0.69, 'val_AUC': 0.82923603, 'epoch': 63},\n",
            "       {'loss': 0.2388286259174347, 'binary_accuracy': 0.69, 'AUC': 0.8051081, 'val_loss': 0.23915612113475798, 'val_binary_accuracy': 0.68, 'val_AUC': 0.817738, 'epoch': 64},\n",
            "       {'loss': 0.23880320084095003, 'binary_accuracy': 0.692, 'AUC': 0.808062, 'val_loss': 0.23911250591278077, 'val_binary_accuracy': 0.686, 'val_AUC': 0.82901406, 'epoch': 65},\n",
            "       {'loss': 0.2388071746826172, 'binary_accuracy': 0.691, 'AUC': 0.80919, 'val_loss': 0.23912235903739928, 'val_binary_accuracy': 0.683, 'val_AUC': 0.822044, 'epoch': 66},\n",
            "       {'loss': 0.23881085789203643, 'binary_accuracy': 0.695, 'AUC': 0.81122, 'val_loss': 0.2391096419095993, 'val_binary_accuracy': 0.688, 'val_AUC': 0.8299979, 'epoch': 67},\n",
            "       {'loss': 0.23881358611583708, 'binary_accuracy': 0.693, 'AUC': 0.81044805, 'val_loss': 0.2391210253238678, 'val_binary_accuracy': 0.685, 'val_AUC': 0.82617795, 'epoch': 68},\n",
            "       {'loss': 0.23882469391822814, 'binary_accuracy': 0.694, 'AUC': 0.81102407, 'val_loss': 0.2391201639175415, 'val_binary_accuracy': 0.685, 'val_AUC': 0.8292001, 'epoch': 69},\n",
            "       {'loss': 0.23882496631145478, 'binary_accuracy': 0.692, 'AUC': 0.81036806, 'val_loss': 0.23914218306541443, 'val_binary_accuracy': 0.682, 'val_AUC': 0.820712, 'epoch': 70},\n",
            "       {'loss': 0.23880903601646422, 'binary_accuracy': 0.691, 'AUC': 0.80842, 'val_loss': 0.23912503170967103, 'val_binary_accuracy': 0.683, 'val_AUC': 0.823746, 'epoch': 71},\n",
            "       {'loss': 0.2388079788684845, 'binary_accuracy': 0.693, 'AUC': 0.809196, 'val_loss': 0.2391103994846344, 'val_binary_accuracy': 0.687, 'val_AUC': 0.82863593, 'epoch': 72},\n",
            "       {'loss': 0.2388167963027954, 'binary_accuracy': 0.693, 'AUC': 0.80538803, 'val_loss': 0.2391275165081024, 'val_binary_accuracy': 0.683, 'val_AUC': 0.822054, 'epoch': 73},\n",
            "       {'loss': 0.23881770122051238, 'binary_accuracy': 0.692, 'AUC': 0.808148, 'val_loss': 0.23912479031085968, 'val_binary_accuracy': 0.683, 'val_AUC': 0.822054, 'epoch': 74},\n",
            "       {'loss': 0.23881075167655944, 'binary_accuracy': 0.692, 'AUC': 0.810356, 'val_loss': 0.23911661744117738, 'val_binary_accuracy': 0.686, 'val_AUC': 0.8291741, 'epoch': 75},\n",
            "       {'loss': 0.23881348991394044, 'binary_accuracy': 0.695, 'AUC': 0.81109, 'val_loss': 0.2391264135837555, 'val_binary_accuracy': 0.685, 'val_AUC': 0.82908607, 'epoch': 76},\n",
            "       {'loss': 0.23880939102172852, 'binary_accuracy': 0.693, 'AUC': 0.81128603, 'val_loss': 0.2391187365055084, 'val_binary_accuracy': 0.685, 'val_AUC': 0.8281779, 'epoch': 77},\n",
            "       {'loss': 0.23880886483192443, 'binary_accuracy': 0.693, 'AUC': 0.8091579, 'val_loss': 0.23912451565265655, 'val_binary_accuracy': 0.685, 'val_AUC': 0.828218, 'epoch': 78},\n",
            "       {'loss': 0.23881305813789366, 'binary_accuracy': 0.691, 'AUC': 0.8081481, 'val_loss': 0.23913285923004152, 'val_binary_accuracy': 0.683, 'val_AUC': 0.822862, 'epoch': 79},\n",
            "       {'loss': 0.2388096534013748, 'binary_accuracy': 0.694, 'AUC': 0.812306, 'val_loss': 0.23911340928077698, 'val_binary_accuracy': 0.687, 'val_AUC': 0.82868797, 'epoch': 80},\n",
            "       {'loss': 0.23880763816833497, 'binary_accuracy': 0.691, 'AUC': 0.81157994, 'val_loss': 0.23912431406974793, 'val_binary_accuracy': 0.685, 'val_AUC': 0.827264, 'epoch': 81},\n",
            "       {'loss': 0.238806809425354, 'binary_accuracy': 0.691, 'AUC': 0.806876, 'val_loss': 0.23912307822704315, 'val_binary_accuracy': 0.684, 'val_AUC': 0.825204, 'epoch': 82},\n",
            "       {'loss': 0.23882174575328827, 'binary_accuracy': 0.696, 'AUC': 0.81255794, 'val_loss': 0.23910523867607117, 'val_binary_accuracy': 0.69, 'val_AUC': 0.83003604, 'epoch': 83},\n",
            "       {'loss': 0.2388201915025711, 'binary_accuracy': 0.691, 'AUC': 0.80510604, 'val_loss': 0.23915474212169646, 'val_binary_accuracy': 0.68, 'val_AUC': 0.8168799, 'epoch': 84},\n",
            "       {'loss': 0.2388086680173874, 'binary_accuracy': 0.691, 'AUC': 0.80709994, 'val_loss': 0.23911284255981446, 'val_binary_accuracy': 0.686, 'val_AUC': 0.830002, 'epoch': 85},\n",
            "       {'loss': 0.23880976092815398, 'binary_accuracy': 0.693, 'AUC': 0.810512, 'val_loss': 0.2391110837459564, 'val_binary_accuracy': 0.687, 'val_AUC': 0.8280679, 'epoch': 86},\n",
            "       {'loss': 0.23880799508094788, 'binary_accuracy': 0.691, 'AUC': 0.8101741, 'val_loss': 0.2391264832019806, 'val_binary_accuracy': 0.683, 'val_AUC': 0.82201004, 'epoch': 87},\n",
            "       {'loss': 0.23880775260925294, 'binary_accuracy': 0.693, 'AUC': 0.810412, 'val_loss': 0.23911040282249452, 'val_binary_accuracy': 0.687, 'val_AUC': 0.827904, 'epoch': 88},\n",
            "       {'loss': 0.23880481910705567, 'binary_accuracy': 0.692, 'AUC': 0.8096859, 'val_loss': 0.23912884044647217, 'val_binary_accuracy': 0.683, 'val_AUC': 0.824294, 'epoch': 89},\n",
            "       {'loss': 0.23881132006645203, 'binary_accuracy': 0.691, 'AUC': 0.80661595, 'val_loss': 0.23913745880126952, 'val_binary_accuracy': 0.682, 'val_AUC': 0.81758404, 'epoch': 90},\n",
            "       {'loss': 0.23880200850963593, 'binary_accuracy': 0.691, 'AUC': 0.808122, 'val_loss': 0.23911365532875062, 'val_binary_accuracy': 0.686, 'val_AUC': 0.82944804, 'epoch': 91},\n",
            "       {'loss': 0.2388122720718384, 'binary_accuracy': 0.691, 'AUC': 0.806944, 'val_loss': 0.23912338924407958, 'val_binary_accuracy': 0.684, 'val_AUC': 0.82434994, 'epoch': 92},\n",
            "       {'loss': 0.23880897128582002, 'binary_accuracy': 0.695, 'AUC': 0.814532, 'val_loss': 0.23911213314533233, 'val_binary_accuracy': 0.687, 'val_AUC': 0.827598, 'epoch': 93},\n",
            "       {'loss': 0.23880674242973327, 'binary_accuracy': 0.695, 'AUC': 0.81302, 'val_loss': 0.23911276054382324, 'val_binary_accuracy': 0.69, 'val_AUC': 0.82975805, 'epoch': 94},\n",
            "       {'loss': 0.23881984317302704, 'binary_accuracy': 0.694, 'AUC': 0.812572, 'val_loss': 0.23913377845287323, 'val_binary_accuracy': 0.684, 'val_AUC': 0.826516, 'epoch': 95},\n",
            "       {'loss': 0.23881175518035888, 'binary_accuracy': 0.691, 'AUC': 0.809632, 'val_loss': 0.23911652636528016, 'val_binary_accuracy': 0.686, 'val_AUC': 0.8291461, 'epoch': 96},\n",
            "       {'loss': 0.2388382294178009, 'binary_accuracy': 0.694, 'AUC': 0.80647206, 'val_loss': 0.23910903954505922, 'val_binary_accuracy': 0.687, 'val_AUC': 0.82867193, 'epoch': 97},\n",
            "       {'loss': 0.23881870436668395, 'binary_accuracy': 0.694, 'AUC': 0.81042403, 'val_loss': 0.23911751437187195, 'val_binary_accuracy': 0.686, 'val_AUC': 0.8291681, 'epoch': 98},\n",
            "       {'loss': 0.23882522654533386, 'binary_accuracy': 0.692, 'AUC': 0.80743796, 'val_loss': 0.23914125657081603, 'val_binary_accuracy': 0.682, 'val_AUC': 0.8184, 'epoch': 99}],\n",
            "      dtype=object), 'model_weights': array([ 8.8740838e-01,  5.6962819e+00, -5.5508539e-02,  4.7184024e+00,\n",
            "        4.8664904e+00,  3.1296399e-01,  4.6454296e+00,  3.6543555e+00,\n",
            "        1.6109911e+00,  4.7911825e+00,  3.5413194e-01,  2.6348860e+00,\n",
            "        5.9223952e+00,  2.6487622e+00,  4.7125115e+00,  1.2048173e+00,\n",
            "        2.5141828e+00,  2.8927550e+00,  4.4965205e+00,  5.4954624e+00,\n",
            "        9.9750727e-01,  5.9994340e+00, -3.4908304e-04,  5.1231112e+00,\n",
            "        2.6524866e+00,  4.7019234e+00,  1.7384317e+00,  8.2696658e-01,\n",
            "        3.9223645e+00,  4.4099178e+00], dtype=float32), 'feature_dimension': array(5), 'encoding_circuit': array('FirstOrderExpansion', dtype='<U19'), 'encoding_map': array('self_product', dtype='<U12'), 'circuit_parameters': array(['θ_0', 'θ_1', 'θ_10', 'θ_11', 'θ_12', 'θ_13', 'θ_14', 'θ_15',\n",
            "       'θ_16', 'θ_17', 'θ_18', 'θ_19', 'θ_2', 'θ_20', 'θ_21', 'θ_22',\n",
            "       'θ_23', 'θ_24', 'θ_25', 'θ_26', 'θ_27', 'θ_28', 'θ_29', 'θ_3',\n",
            "       'θ_4', 'θ_5', 'θ_6', 'θ_7', 'θ_8', 'θ_9'], dtype='<U4'), 'num_parameters': array(30), 'variational_circuit': array('EfficientSU2', dtype='<U12'), 'qubits': array([cirq.GridQubit(-1, -1), cirq.GridQubit(0, 0), cirq.GridQubit(0, 1),\n",
            "       cirq.GridQubit(0, 2), cirq.GridQubit(0, 3), cirq.GridQubit(0, 4)],\n",
            "      dtype=object), 'n_qubit': array(6), 'differentiator': array('', dtype='<U1'), 'activation': array('sigmoid', dtype='<U7'), 'optimizer': array('Adam', dtype='<U4'), 'metrics': array(['binary_accuracy', 'AUC'], dtype='<U15'), 'loss': array(['mean_squared_error'], dtype='<U18'), 'train_size': array(1000), 'val_size': array(1000), 'test_size': array(1000), 'batch_size': array(64), 'epochs': array(100), 'time': array('2020-08-09_14-26-52', dtype='<U19'), 'roc_result': array({'fpr': array([0.   , 0.   , 0.   , 0.002, 0.002, 0.004, 0.004, 0.006, 0.006,\n",
            "       0.008, 0.008, 0.01 , 0.01 , 0.012, 0.012, 0.014, 0.014, 0.016,\n",
            "       0.016, 0.018, 0.018, 0.02 , 0.02 , 0.022, 0.022, 0.024, 0.024,\n",
            "       0.026, 0.026, 0.028, 0.028, 0.03 , 0.03 , 0.032, 0.032, 0.034,\n",
            "       0.034, 0.036, 0.036, 0.038, 0.038, 0.04 , 0.04 , 0.044, 0.044,\n",
            "       0.046, 0.046, 0.048, 0.048, 0.052, 0.052, 0.054, 0.054, 0.056,\n",
            "       0.056, 0.058, 0.058, 0.06 , 0.06 , 0.064, 0.064, 0.066, 0.066,\n",
            "       0.068, 0.068, 0.072, 0.072, 0.072, 0.072, 0.074, 0.074, 0.076,\n",
            "       0.076, 0.078, 0.078, 0.08 , 0.08 , 0.082, 0.082, 0.086, 0.086,\n",
            "       0.088, 0.088, 0.09 , 0.09 , 0.092, 0.092, 0.094, 0.094, 0.098,\n",
            "       0.098, 0.1  , 0.1  , 0.102, 0.102, 0.106, 0.106, 0.11 , 0.11 ,\n",
            "       0.112, 0.112, 0.116, 0.116, 0.118, 0.118, 0.12 , 0.12 , 0.122,\n",
            "       0.122, 0.124, 0.124, 0.126, 0.126, 0.128, 0.128, 0.13 , 0.13 ,\n",
            "       0.132, 0.132, 0.134, 0.134, 0.138, 0.138, 0.14 , 0.14 , 0.144,\n",
            "       0.144, 0.148, 0.148, 0.15 , 0.15 , 0.152, 0.152, 0.156, 0.156,\n",
            "       0.158, 0.158, 0.162, 0.162, 0.168, 0.168, 0.172, 0.172, 0.178,\n",
            "       0.178, 0.184, 0.184, 0.188, 0.188, 0.192, 0.192, 0.194, 0.194,\n",
            "       0.204, 0.204, 0.206, 0.206, 0.208, 0.208, 0.21 , 0.21 , 0.218,\n",
            "       0.218, 0.22 , 0.22 , 0.226, 0.226, 0.228, 0.228, 0.23 , 0.23 ,\n",
            "       0.236, 0.236, 0.242, 0.242, 0.244, 0.244, 0.246, 0.246, 0.248,\n",
            "       0.248, 0.258, 0.258, 0.262, 0.262, 0.264, 0.264, 0.266, 0.266,\n",
            "       0.274, 0.274, 0.278, 0.278, 0.284, 0.284, 0.292, 0.292, 0.296,\n",
            "       0.296, 0.302, 0.302, 0.304, 0.304, 0.322, 0.322, 0.326, 0.326,\n",
            "       0.332, 0.332, 0.342, 0.342, 0.346, 0.346, 0.348, 0.348, 0.352,\n",
            "       0.352, 0.354, 0.354, 0.356, 0.356, 0.36 , 0.36 , 0.368, 0.368,\n",
            "       0.37 , 0.37 , 0.372, 0.372, 0.376, 0.376, 0.386, 0.386, 0.388,\n",
            "       0.388, 0.392, 0.392, 0.394, 0.394, 0.402, 0.402, 0.404, 0.404,\n",
            "       0.408, 0.408, 0.424, 0.424, 0.426, 0.426, 0.442, 0.442, 0.468,\n",
            "       0.468, 0.48 , 0.48 , 0.486, 0.486, 0.494, 0.494, 0.502, 0.502,\n",
            "       0.514, 0.514, 0.528, 0.528, 0.53 , 0.53 , 0.534, 0.534, 0.54 ,\n",
            "       0.54 , 0.544, 0.544, 0.57 , 0.57 , 0.578, 0.578, 0.582, 0.582,\n",
            "       0.586, 0.586, 0.598, 0.598, 0.612, 0.612, 0.626, 0.626, 0.628,\n",
            "       0.628, 0.632, 0.632, 0.64 , 0.64 , 0.642, 0.642, 0.666, 0.666,\n",
            "       0.672, 0.672, 0.698, 0.698, 0.704, 0.704, 0.706, 0.706, 0.728,\n",
            "       0.728, 0.746, 0.746, 0.754, 0.758, 0.772, 0.772, 0.788, 0.788,\n",
            "       0.792, 0.792, 0.816, 0.816, 0.818, 0.818, 0.828, 0.828, 0.85 ,\n",
            "       0.85 , 0.86 , 0.86 , 0.862, 0.866, 0.874, 0.874, 0.894, 0.894,\n",
            "       0.94 , 0.94 , 0.946, 0.946, 0.98 , 0.98 , 0.99 , 0.99 , 0.998,\n",
            "       0.998, 1.   ]), 'tpr': array([0.   , 0.002, 0.006, 0.006, 0.01 , 0.01 , 0.058, 0.058, 0.09 ,\n",
            "       0.09 , 0.094, 0.094, 0.102, 0.102, 0.166, 0.166, 0.168, 0.168,\n",
            "       0.184, 0.184, 0.204, 0.204, 0.224, 0.224, 0.226, 0.226, 0.256,\n",
            "       0.256, 0.258, 0.258, 0.302, 0.302, 0.312, 0.312, 0.314, 0.314,\n",
            "       0.316, 0.316, 0.32 , 0.32 , 0.324, 0.324, 0.342, 0.342, 0.348,\n",
            "       0.348, 0.386, 0.386, 0.392, 0.392, 0.414, 0.414, 0.428, 0.428,\n",
            "       0.438, 0.438, 0.44 , 0.44 , 0.456, 0.456, 0.462, 0.462, 0.464,\n",
            "       0.464, 0.47 , 0.47 , 0.48 , 0.484, 0.494, 0.494, 0.51 , 0.51 ,\n",
            "       0.516, 0.516, 0.518, 0.518, 0.532, 0.532, 0.536, 0.536, 0.538,\n",
            "       0.538, 0.542, 0.542, 0.544, 0.544, 0.548, 0.548, 0.552, 0.552,\n",
            "       0.554, 0.554, 0.568, 0.568, 0.572, 0.572, 0.576, 0.576, 0.58 ,\n",
            "       0.58 , 0.586, 0.586, 0.598, 0.598, 0.602, 0.602, 0.606, 0.606,\n",
            "       0.616, 0.616, 0.618, 0.618, 0.62 , 0.62 , 0.622, 0.622, 0.624,\n",
            "       0.624, 0.626, 0.626, 0.63 , 0.63 , 0.632, 0.632, 0.644, 0.644,\n",
            "       0.652, 0.652, 0.658, 0.658, 0.662, 0.662, 0.664, 0.664, 0.668,\n",
            "       0.668, 0.676, 0.676, 0.68 , 0.68 , 0.682, 0.682, 0.684, 0.684,\n",
            "       0.69 , 0.69 , 0.692, 0.692, 0.696, 0.696, 0.7  , 0.7  , 0.702,\n",
            "       0.702, 0.706, 0.706, 0.708, 0.708, 0.71 , 0.71 , 0.712, 0.712,\n",
            "       0.72 , 0.72 , 0.722, 0.722, 0.724, 0.724, 0.73 , 0.73 , 0.732,\n",
            "       0.732, 0.734, 0.734, 0.736, 0.736, 0.738, 0.738, 0.74 , 0.74 ,\n",
            "       0.754, 0.754, 0.764, 0.764, 0.766, 0.766, 0.77 , 0.77 , 0.78 ,\n",
            "       0.78 , 0.786, 0.786, 0.79 , 0.79 , 0.792, 0.792, 0.794, 0.794,\n",
            "       0.796, 0.796, 0.798, 0.798, 0.8  , 0.8  , 0.802, 0.802, 0.806,\n",
            "       0.806, 0.81 , 0.81 , 0.812, 0.812, 0.814, 0.814, 0.818, 0.818,\n",
            "       0.822, 0.822, 0.824, 0.824, 0.826, 0.826, 0.836, 0.836, 0.838,\n",
            "       0.838, 0.842, 0.842, 0.844, 0.844, 0.846, 0.846, 0.848, 0.848,\n",
            "       0.85 , 0.85 , 0.852, 0.852, 0.856, 0.856, 0.862, 0.862, 0.864,\n",
            "       0.864, 0.87 , 0.87 , 0.872, 0.872, 0.874, 0.874, 0.876, 0.876,\n",
            "       0.878, 0.878, 0.88 , 0.88 , 0.886, 0.886, 0.888, 0.888, 0.892,\n",
            "       0.892, 0.898, 0.898, 0.902, 0.902, 0.906, 0.906, 0.908, 0.908,\n",
            "       0.912, 0.912, 0.914, 0.914, 0.916, 0.916, 0.918, 0.918, 0.92 ,\n",
            "       0.92 , 0.922, 0.922, 0.924, 0.924, 0.926, 0.926, 0.928, 0.928,\n",
            "       0.932, 0.932, 0.936, 0.936, 0.938, 0.938, 0.94 , 0.94 , 0.942,\n",
            "       0.942, 0.946, 0.946, 0.95 , 0.95 , 0.952, 0.952, 0.954, 0.954,\n",
            "       0.956, 0.956, 0.958, 0.958, 0.958, 0.958, 0.96 , 0.96 , 0.962,\n",
            "       0.962, 0.964, 0.964, 0.966, 0.966, 0.972, 0.972, 0.978, 0.978,\n",
            "       0.98 , 0.98 , 0.982, 0.982, 0.982, 0.982, 0.984, 0.984, 0.988,\n",
            "       0.988, 0.99 , 0.99 , 0.994, 0.994, 0.996, 0.996, 0.998, 0.998,\n",
            "       1.   , 1.   ]), 'auc': 0.823332}, dtype=object)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8j9aHfcn2tZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "a1b6cbc6-1070-4221-b041-ab506c3b221c"
      },
      "source": [
        "#display the roc curve\n",
        "from IPython.display import Image\n",
        "roc_image = glob.glob('logs/*.png')[0]\n",
        "Image(filename=roc_image) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ07X_sqtJUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}